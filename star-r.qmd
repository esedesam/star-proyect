---
title: "Proyecto STAR"
subtitle: "Inferencia Causal"
description: "Máster en Ciencia de Datos (UV)"
author: "Adrián Lara, Jesús Martínez, Miguel Muñoz, Samuel Ortega & Pablo Vicente"
date: last-modified
date-format: "DD-MM-YYYY"
title-block-banner: "#B0C8D6"
format: 
  html:
    embed-resources: true
    smooth-scroll: true
    toc: true
    toc_float: yes
    theme: cosmo
    fontcolor: black
editor: source
execute: 
  echo: false
  warning: false
  error: false
  message: false
  include: true
lang: es
css: utilities/qmdStyle.css
---

# Proyecto *STAR*

```{r setup}
#| include: false

# Cargar pacman
if (!require("pacman", quietly = TRUE)) {
  install.packages("pacman")
  library(pacman)
}

# Cargar los paquetes necesarios
p_load(AER, ggplot2, ggthemes, dplyr, tidyr, knitr, stargazer, sandwich)

# Ajustes adicionales
theme_set(
  theme_minimal() +
    theme(
      panel.border = element_rect(color = "black", fill = NA),
      axis.ticks = element_line(color = "black")))

defaultFillColor <- "steelblue"
update_geom_defaults("bar", aes(fill = defaultFillColor))
update_geom_defaults("boxplot", aes(fill = defaultFillColor))

# Definición de funciones
plotCombinedFeature <- function(starDf, featureId, featureLabel = NA, isNumeric = TRUE, removeNa = FALSE) {
  if (is.na(featureLabel)) {
    featureLabel <- featureId
  }
  plotDf <- pivot_longer(
    starDf,
    cols = grep(paste0("^", featureId, ".{1}$"), colnames(starDf), value = TRUE),
    names_to = "grade",
    values_to = "value")
  
  featureLevels <- paste0(featureId, c("k", "1", "2", "3"))
  plotDf$grade <- factor(
    plotDf$grade,
    levels = featureLevels,
    labels = c("Kindergarden", "Primero", "Segundo", "Tercero"),
    ordered = TRUE)
  
  if (removeNa) {
    plotDf <- na.omit(plotDf[, c("grade", "value")])
  }
  
  if (isNumeric) {
    ggplot(plotDf, aes(x = grade, y = value)) +
      geom_boxplot() +
      labs(x = "Curso", y = featureLabel)
  } else {
    ggplot(plotDf, aes(x = value, fill = grade)) +
      geom_bar(position = "dodge") +
      labs(x = featureLabel, y = "Frecuencia acumulada", fill = "Curso")
  }
}

# Numerización automática en tablas y figuras


capTabNo <- 2 
capFigNo <- 1

capTab <- function(x){
  x <- paste0("<strong>Tabla ", capTabNo,". </strong> ", x)
  capTabNo <<- capTabNo + 1
  x
}

capFig <- function(x, y){
  x <- paste0("<strong>Figura ", capFigNo, ".</strong> ", x, " \\label{fig:", y, "}")
  capFigNo <<- capFigNo + 1
  x
}
```

## Introducción

El proyecto *STAR* (*Student-Teacher Achievement Ratio*) es un estudio sobre el tamaño de las clases llevado a cabo en Tennessee en tres fases, diseñado para determinar el efecto del **tamaño reducido de las clases** en los primeros grados sobre el **rendimiento académico** a corto y largo plazo de los alumnos. Se inspiró en un estudio prometedor realizado en Indiana sobre los beneficios de las clases pequeñas, pero también consideró los costos adicionales de más aulas y profesores. La legislatura de Tennessee autorizó este estudio de **cuatro años** para obtener datos sobre la eficacia de las clases reducidas.

Se compararon los resultados de alumnos en **jardines de infancia** y en los **primeros tres grados**, en clases pequeñas de **13 a 17 alumnos**, clases regulares de **22 a 25 alumnos** y clases regulares con un **profesor particular**. Aproximadamente 6500 alumnos en 330 aulas de unas 80 escuelas fueron evaluados en **lectura**, **matemáticas** y habilidades básicas de estudio mediante [pruebas estandarizadas](https://en.wikipedia.org/wiki/Stanford_Achievement_Test_Series). Después de los cuatro años, se comprobó que las clases pequeñas mejoraron significativamente el aprendizaje temprano y los estudios cognitivos. En cualquier año de calendario, el experimento se llevó a cabo en solo uno de los grados, minimizando así el número de clases necesitadas.

```{r, groupsSTAR}
groupsTable <- data.frame(
  Grado = c("K", "1", "2", "3"),
  `Tratamiento 1` = c("Clase pequeña", "Clase pequeña", "Clase pequeña", "Clase pequeña"),
  `Tratamiento 2` = c("Clase regular + asistente", "Clase regular + asistente", "Clase regular + asistente", "Clase regular + asistente"),
  Control = c("Clase regular", "Clase regular", "Clase regular", "Clase regular")
)
kable(groupsTable, caption = "<strong>Tabla 1. </strong> Grupos de control y tratamiento en el experimento STAR")
```

Los datos del estudio están disponibles en el paquete `AER` de `R`.

## Descripción del problema

En primer lugar, cargamos los datos a nuestro espacio de trabajo.

```{r cargar-datos}
#| echo: true
data(STAR)
starDf <- STAR
```

Encontramos con las siguientes características:

1.  **gender**: Factor que indica el género del estudiante.

2.  **ethnicity**: Factor que indica la etnicidad del estudiante con niveles "cauc" (Caucásico), "afam" (Afroamericano), "asian" (Asiático), "hispanic" (Hispano), "amindian" (Indio Americano) o "other" (Otro).

3.  **birth**: Trimestre de nacimiento del estudiante (del año de clase).

4.  **stark**: Factor que indica el tipo de clase STAR en jardín de infancia: regular, pequeña o regular-con-ayudante. NA indica que no asistió a ninguna clase STAR.

5.  **star1**: Factor que indica el tipo de clase STAR en primer grado: regular, pequeña o regular-con-ayudante. NA indica que no asistió a ninguna clase STAR.

6.  **star2**: Factor que indica el tipo de clase STAR en segundo grado: regular, pequeña o regular-con-ayudante. NA indica que no asistió a ninguna clase STAR.

7.  **star3**: Factor que indica el tipo de clase STAR en tercer grado: regular, pequeña o regular-con-ayudante. NA indica que no asistió a ninguna clase STAR.

8.  **readk**: Puntuación total de lectura en jardín de infancia.

9.  **read1**: Puntuación total de lectura en primer grado.

10. **read2**: Puntuación total de lectura en segundo grado.

11. **read3**: Puntuación total de lectura en tercer grado.

12. **mathk**: Puntuación total de matemáticas en jardín de infancia.

13. **math1**: Puntuación total de matemáticas en primer grado.

14. **math2**: Puntuación total de matemáticas en segundo grado.

15. **math3**: Puntuación total de matemáticas en tercer grado.

16. **lunchk**: Factor que indica si el estudiante calificó para almuerzo gratuito en jardín de infancia.

17. **lunch1**: Factor que indica si el estudiante calificó para almuerzo gratuito en primer grado.

18. **lunch2**: Factor que indica si el estudiante calificó para almuerzo gratuito en segundo grado.

19. **lunch3**: Factor que indica si el estudiante calificó para almuerzo gratuito en tercer grado.

20. **schoolk**: Factor que indica el tipo de escuela en jardín de infancia: "inner-city" (ciudad interior), "suburban" (suburbana), "rural" (rural) o "urban" (urbana).

21. **school1**: Factor que indica el tipo de escuela en primer grado: "inner-city" (ciudad interior), "suburban" (suburbana), "rural" (rural) o "urban" (urbana).

22. **school2**: Factor que indica el tipo de escuela en segundo grado: "inner-city" (ciudad interior), "suburban" (suburbana), "rural" (rural) o "urban" (urbana).

23. **school3**: Factor que indica el tipo de escuela en tercer grado: "inner-city" (ciudad interior), "suburban" (suburbana), "rural" (rural) o "urban" (urbana).

24. **degreek**: Factor que indica el título más alto del maestro en jardín de infancia: "bachelor" (licenciatura), "master" (maestría), "specialist" (especialista) o "master+" (maestría+).

25. **degree1**: Factor que indica el título más alto del maestro en primer grado: "bachelor" (licenciatura), "master" (maestría), "specialist" (especialista) o "phd" (doctorado).

26. **degree2**: Factor que indica el título más alto del maestro en segundo grado: "bachelor" (licenciatura), "master" (maestría), "specialist" (especialista) o "phd" (doctorado).

27. **degree3**: Factor que indica el título más alto del maestro en tercer grado: "bachelor" (licenciatura), "master" (maestría), "specialist" (especialista) o "phd" (doctorado).

28. **ladderk**: Factor que indica el nivel de carrera del maestro en jardín de infancia: "level1" (nivel 1), "level2" (nivel 2), "level3" (nivel 3), "apprentice" (aprendiz), "probation" (en prueba) o "pending" (pendiente).

29. **ladder1**: Factor que indica el nivel de carrera del maestro en primer grado: "level1" (nivel 1), "level2" (nivel 2), "level3" (nivel 3), "apprentice" (aprendiz), "probation" (en prueba) o "noladder" (sin nivel).

30. **ladder2**: Factor que indica el nivel de carrera del maestro en segundo grado: "level1" (nivel 1), "level2" (nivel 2), "level3" (nivel 3), "apprentice" (aprendiz), "probation" (en prueba) o "noladder" (sin nivel).

31. **ladder3**: Factor que indica el nivel de carrera del maestro en tercer grado: "level1" (nivel 1), "level2" (nivel 2), "level3" (nivel 3), "apprentice" (aprendiz), "probation" (en prueba) o "noladder" (sin nivel).

32. **experiencek**: Años de experiencia total del maestro en jardín de infancia.

33. **experience1**: Años de experiencia total del maestro en primer grado.

34. **experience2**: Años de experiencia total del maestro en segundo grado.

35. **experience3**: Años de experiencia total del maestro en tercer grado.

36. **tethnicityk**: Factor que indica la etnicidad del maestro en jardín de infancia con niveles "cauc" (Caucásico) o "afam" (Afroamericano).

37. **tethnicity1**: Factor que indica la etnicidad del maestro en primer grado con niveles "cauc" (Caucásico) o "afam" (Afroamericano).

38. **tethnicity2**: Factor que indica la etnicidad del maestro en segundo grado con niveles "cauc" (Caucásico) o "afam" (Afroamericano).

39. **tethnicity3**: Factor que indica la etnicidad del maestro en tercer grado con niveles "cauc" (Caucásico), "afam" (Afroamericano) o "asian" (Asiático).

40. **systemk**: Factor que indica el ID del sistema escolar en jardín de infancia.

41. **system1**: Factor que indica el ID del sistema escolar en primer grado.

42. **system2**: Factor que indica el ID del sistema escolar en segundo grado.

43. **system3**: Factor que indica el ID del sistema escolar en tercer grado.

44. **schoolidk**: Factor que indica el ID de la escuela en jardín de infancia.

45. **schoolid1**: Factor que indica el ID de la escuela en primer grado.

46. **schoolid2**: Factor que indica el ID de la escuela en segundo grado.

47. **schoolid3**: Factor que indica el ID de la escuela en tercer grado.

### Análisis exploratorio de datos

Observamos que hay una gran cantidad de datos faltantes en la mayor parte de las variables.

```{r aed-na, fig.cap=capFig("Porcentaje de valores faltantes en las variables del conjunto de datos.", y = "aed-na")}
na_counts <- sapply(starDf, function(x) sum(is.na(x)))
total_counts <- nrow(starDf)

na_percentage <- (na_counts / total_counts) * 100

na_percentage_df <- data.frame(
  Column = names(na_percentage),
  NA_Percentage = as.numeric(na_percentage)
)

ggplot(na_percentage_df, aes(x = Column, y = NA_Percentage)) +
  geom_bar(stat = "identity") +
  labs(x = "Característica",
       y = "Porcentaje de NA (%)") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_y_continuous(labels = scales::percent_format(scale = 1))
```

Esto se debe a la naturaleza de los datos: por ejemplo, consideremos la primera observación.

```{r aed-na-ejemplo}
starDf[1, ]
```

En la salida encontramos que el estudiante ingresó al experimento en tercer grado en una clase regular, por lo que el tamaño de la clase se registra en star3 y las otras variables indicadoras de tipo de clase son `NA`. De la misma manera, sus puntuaciones de matemáticas y lectura para el tercer grado están disponibles; sin embargo, los valores de estas variables para otros grados no están presentes por la misma razón.

A modo de comprobación, nos aseguramos todas las entradas corresponden a estudiantes que participaron en el proyecto *STAR* al menos durante uno de los cuatro años.

```{r}
nAllStarsNA <- sum(rowSums(is.na(starDf[, c("stark", "star1", "star2", "star3")])) == 4)
cat("Número de entradas sin participaciones:", nAllStarsNA)
```

A continuación, analizamos las distribuciones de las variables descritas.

```{r aed-genero, fig.cap=capFig("Diagrama de barras del género de los estudiantes.", y = "aed-genero")}
ggplot(starDf, aes(x = gender)) +
  geom_bar() +
  labs(x = "Género", y = "Frecuencia acumulada")
```

```{r aed-etnicidad, fig.cap=capFig("Diagrama de barras de la etnicidad de los estudiantes.", y = "aed-etnicidad")}
ggplot(starDf, aes(x = ethnicity)) +
  geom_bar() +
  labs(x = "Etnicidad", y = "Frecuencia acumulada")
```

```{r aed-trim-nac, fig.cap=capFig("Diagrama de barras del trimestre de nacimiento de los estudiantes.", y = "aed-trim-nac")}
ggplot(starDf, aes(x = birth)) +
  geom_bar() +
  labs(x = "Trimestre de nacimiento", y = "Frecuencia acumulada")
```
```{r aed-star, fig.cap=capFig("Diagrama de barras del tipo de clase STAR de los estudiantes.", y = "aed-star")}
starDf %>%
  summarise(
    Kindergarden = sum(!is.na(stark)),
    Primero = sum(!is.na(star1)),
    Segundo = sum(!is.na(star2)),
    Tercero = sum(!is.na(star3))
  ) %>%
  pivot_longer(cols = everything(), names_to = "Curso", values_to = "Observaciones") %>%
  ggplot(aes(x = Curso, y = Observaciones, fill = Observaciones)) +
  geom_bar(stat = "identity") +
  labs(x = "Curso", y = "Número de observaciones", fill = "Número de observaciones") +
  scale_fill_gradient(low = "blue", high = "red")
```




```{r aed-grupo, fig.cap=capFig("Diagrama de barras del grupo experimental de todos los cursos.", y = "aed-grupo")}
plotCombinedFeature(starDf, "star", "Grupo experimental", isNumeric = FALSE)
```

```{r aed-lectura, fig.cap=capFig("Boxplot de la puntuación de lectura de todos los cursos.", y = "aed-lectura")}
plotCombinedFeature(starDf, "read", "Puntuación de lectura")
```

```{r aed-mate, fig.cap=capFig("Boxplot de la puntuación de matemáticas de todos los cursos.", y = "aed-mate")}
plotCombinedFeature(starDf, "math", "Puntuación de matemáticas")
```

```{r aed-almuerzo, fig.cap=capFig("Diagrama de barras de la participación en el almuerzo gratuito de todos los cursos.", y = "aed-almuerzo")}
plotCombinedFeature(starDf, "lunch", "Almuerzo", isNumeric = FALSE)
```

```{r aed-tipo-escuela, fig.cap=capFig("Diagrama de barras del tipo de escuela de todos los cursos.", y = "aed-tipo-escuela")}
plotCombinedFeature(starDf, "school", "Tipo de escuela", isNumeric = FALSE)
```

```{r aed-titulo-maestro, fig.cap=capFig("Diagrama de barras del máximo título académico del maestro de todos los cursos.", y = "aed-titulo-maestro")}
plotCombinedFeature(starDf, "degree", "Título académico", isNumeric = FALSE)
```

```{r aed-nivel-carrera, fig.cap=capFig("Diagrama de barras del nivel de carrera del maestro de todos los cursos.", y = "aed-nivel-carrera")}
plotCombinedFeature(starDf, "ladder", "Nivel de carrera", isNumeric = FALSE)
```

```{r aed-exp, fig.cap=capFig("Boxplot de la experiencia del maestro de todos los cursos.", y = "aed-exp")}
plotCombinedFeature(starDf, "experience", "Experiencia del maestro (años)")
```

```{r aed-etnicidad-maestro, fig.cap=capFig("Diagrama de barras de la etnicidad del maestro de todos los cursos.", y = "aed-etnicidad-maestro")}
plotCombinedFeature(starDf, "tethnicity", "Etnicidad del maestro", isNumeric = FALSE)
```

```{r aed-id-escuela, fig.cap=capFig("Diagrama de barras de la etnicidad del maestro de todos los cursos.", y = "aed-id-escuela")}
plotCombinedFeature(starDf, "schoolid", "Identificador de escuela", isNumeric = FALSE, removeNa = TRUE)
```

### Identificación de efecto y tratamiento

En el proyecto *STAR*, el tratamiento aplicado es la pertenencia a clases reducidas y a clases normales con ayuda, frente a clases normales sin ayuda. En este trabajo, convertimos este tratamiento en dos tratamientos binarios:

-   Clase reducida frente a clase normal
-   Clase normal con ayuda frente a clase normal sin ayuda

Por otra parte, escogemos como efecto la variación de una nueva variable **mark**, definida como la suma de las puntuaciones en lectura y matemáticas, habitual en la literatura relacionada con este estudio.

Además, realizamos el análisis para cada año de manera independiente.

### Distribuciones para las variables mirando por la variable de tratamiento

```{r gender-by-treatment, fig.cap=capFig("Diagrama de barras del género de los estudiantes por tratamiento.", y = "gender-by-treatment")}
starDf %>%
  filter(!is.na(stark) & !is.na(gender) & !is.na(star1) & !is.na(star2) & !is.na(star3)) %>%
  pivot_longer(cols = c(stark, star1, star2, star3), names_to = "treatment", values_to = "value") %>%
  ggplot(aes(x = gender, fill = value)) +
  geom_bar(position = "dodge") +
  labs(x = "Género", y = "Frecuencia acumulada", fill = "Tratamiento") +
  facet_wrap(~treatment) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r ethnicity-by-treatment, fig.cap=capFig("Diagrama de barras de la etnicidad de los estudiantes por tratamiento", y = "ethnicity-by-treatment")}
# Agrupar ethnicity en cauc, afam y other
starDf$ethnicity_grouped <- ifelse(starDf$ethnicity == "cauc", "cauc", "afam + other")

starDf %>%
  mutate(ethnicity_grouped = ifelse(ethnicity == "cauc", "cauc", "afam + other")) %>%
  filter(!is.na(stark) & !is.na(ethnicity_grouped) & !is.na(star1) & !is.na(star2) & !is.na(star3)) %>%
  pivot_longer(cols = c(stark, star1, star2, star3), names_to = "treatment", values_to = "value") %>%
  ggplot(aes(x = ethnicity_grouped, fill = value)) +
  geom_bar(position = "dodge") +
  labs(x = "Etnicidad", y = "Frecuencia acumulada", fill = "Tratamiento") +
  facet_wrap(~treatment) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r experience-by-treatment, fig.cap=capFig("Boxplot de la experiencia del maestro por tratamiento.", y = "experience-by-treatment")}
starDf %>%
  filter(!is.na(stark) & !is.na(experiencek) & !is.na(star1) & !is.na(star2) & !is.na(star3)) %>%
  pivot_longer(cols = c(stark, star1, star2, star3), names_to = "treatment", values_to = "value") %>%
  ggplot(aes(x = experiencek, fill = value)) +
  geom_density(alpha = 0.5) +  # Utilizamos geom_density para una distribución más suave
  labs(x = "Experiencia (años)", y = "Densidad", fill = "Tratamiento") +
  facet_wrap(~treatment) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r school-by-treatment, fig.cap=capFig("Diagrama de barras del tipo de escuela por tratamiento.", y = "school-by-treatment")}
starDf %>%
  filter(!is.na(stark) & !is.na(star1) & !is.na(star2) & !is.na(star3)) %>%
  pivot_longer(cols = c(stark, star1, star2, star3), names_to = "treatment", values_to = "value") %>%
  ggplot(aes(x = schoolk, fill = value)) +
  geom_bar(position = "dodge") +
  labs(x = "Tipo de escuela", y = "Frecuencia acumulada", fill = "Tratamiento") +
  facet_wrap(~treatment) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Vemos que en general las distribuciones no son muy diferentes para los distintos tratamientos.

## Análisis causal

Crearemos en primer lugar una nueva variable que sea la suma de las puntuaciones de lectura y matemáticas para cada curso.

```{r mark-variables}
starDf$markK <- starDf$readk + starDf$mathk
starDf$mark1 <- starDf$read1 + starDf$math1
starDf$mark2 <- starDf$read2 + starDf$math2
starDf$mark3 <- starDf$read3 + starDf$math3
```


### Estimación naive del efecto del tratamiento

Para obtener una primera estimación del efecto medio del tratamiento (AET) para cada curso podemos emplear el estimador diferencia en medias (DIM), definido como el valor promedio de la respuesta de los tratados menos el valor promedio de la respuesta para los no tratados. En ausencia de independencia, independencia condicional o asigación aleatoria del tratamiento, este es un estimador sesgado y es distinto al efecto medio del tratamiento.

Según la documentación del estudio, tanto la asignación de alumnos como de profesores fue totalmente aleatoria, por lo que podemos tomar el DIM como una primera estimación válida del ATE con la que comparar el resto de estimaciones que realizaremos más adelante.

```{r mean-differences-naive}
small_regular_k <- round(mean(starDf$markK[starDf$stark == "small"], na.rm = TRUE) - mean(starDf$markK[starDf$stark == "regular"], na.rm = TRUE), 3)
small_regular_1 <- round(mean(starDf$mark1[starDf$star1 == "small"], na.rm = TRUE) - mean(starDf$mark1[starDf$star1 == "regular"], na.rm = TRUE), 3)
small_regular_2 <- round(mean(starDf$mark2[starDf$star2 == "small"], na.rm = TRUE) - mean(starDf$mark2[starDf$star2 == "regular"], na.rm = TRUE), 3)
small_regular_3 <- round(mean(starDf$mark3[starDf$star3 == "small"], na.rm = TRUE) - mean(starDf$mark3[starDf$star3 == "regular"], na.rm = TRUE), 3)
regularAide_regular_k <- round(mean(starDf$markK[starDf$stark == "regular+aide"], na.rm = TRUE) - mean(starDf$markK[starDf$stark == "regular"], na.rm = TRUE), 3)
regularAide_regular_1 <- round(mean(starDf$mark1[starDf$star1 == "regular+aide"], na.rm = TRUE) - mean(starDf$mark1[starDf$star1 == "regular"], na.rm = TRUE), 3)
regularAide_regular_2 <- round(mean(starDf$mark2[starDf$star2 == "regular+aide"], na.rm = TRUE) - mean(starDf$mark2[starDf$star2 == "regular"], na.rm = TRUE), 3)
regularAide_regular_3 <- round(mean(starDf$mark3[starDf$star3 == "regular+aide"], na.rm = TRUE) - mean(starDf$mark3[starDf$star3 == "regular"], na.rm = TRUE), 3)

naiveEstimates <- rbind(c(small_regular_k, small_regular_1, small_regular_2, small_regular_3),
                        c(regularAide_regular_k, regularAide_regular_1, regularAide_regular_2, regularAide_regular_3))

rownames(naiveEstimates) <- c("Small - Regular", "Regular+Aide - Regular")
colnames(naiveEstimates) <- c("K", "1", "2", "3")

kable(naiveEstimates, caption = capTab("Estimaciones naive del efecto del tratamiento para los diferentes cursos"))
```

Estos resultados son exactamente los mismos que los que se mostrarán a continuación con el modelo básico de regresión lineal. Sin embargo, lo siguiente será más riguroso al incluir también errores y cuestiones de significancia.

### Modelo de regresión

#### Modelo básico

Consideramos el modelo:

$Y = \beta_0 + \beta_1 * SmallClass + \beta_2 * RegularClassWithAide + \epsilon$

donde $Y$ es la variable respuesta que nos será de interés, $\beta_0$ es el intercepto, $\beta_1$ es el indicador de la clase pequeña, $\beta_2$ es el indicador de la clase regular con ayuda. $\epsilon$ es el término de ruido usual incorporado en el modelo.

Se toma en primer lugar a $Y = \text{mark}$, la suma de las puntuaciones de lectura y matemáticas (read + math).

Se calculan a continuación modelos lineales de regresión siguiendo la expresión anterior para cada uno de los cursos. Se calcularán también los errores estándar robustos para cada uno de los coeficientes (uso de la función `vcovHC` que contiene la matriz de covarianza robusta de los coeficientes estimados). Estos se utilizan para corregir los problemas de heterocedasticidad (cuando la varianza de los errores no es constante) en los modelos de regresión.


```{r mean-differences-basicModel}
basicModelk <- lm(readk + mathk ~ stark, data = starDf)
basicModel1 <- lm(read1 + math1 ~ star1, data = starDf)
basicModel2 <- lm(read2 + math2 ~ star2, data = starDf)
basicModel3 <- lm(read3 + math3 ~ star3, data = starDf)

rob_se_1 <- list(sqrt(diag(vcovHC(basicModelk, type = "HC1"))),
                 sqrt(diag(vcovHC(basicModel1, type = "HC1"))),
                 sqrt(diag(vcovHC(basicModel2, type = "HC1"))),
                 sqrt(diag(vcovHC(basicModel3, type = "HC1"))))
```

```{r mean-differences-summarybasicModel, include = FALSE}
html_basicModel <- stargazer(basicModelk, basicModel1, basicModel2, basicModel3,
  title = capTab("Proyecto STAR: Estimación de diferencias, modelo básico"),
  header = FALSE, 
  model.numbers = F,
  omit.table.layout = "n",
  digits = 3, 
  type = "html",
  column.labels = c("K", "1", "2", "3"),
  dep.var.caption  = "Variable dependiente: Curso",
  dep.var.labels.include = FALSE,
  se = rob_se_1)

# quitar primer lista de la tabla esta
html_basicModel <- html_basicModel[2:length(html_basicModel)]
```


`r html_basicModel`

Los resultados de la Tabla anterior dejan claro que hay un incremento del rendimiento del estudiante cuando está en clases reducidas (ver valores de los coeficientes, que además son muy significativos '***'). Las estimaciones están entre 13.899 y 29.781, si bien es cierto que el efecto en el curso 1 se separa un poco de los demás. Esto podría deberse a que en alguno de los años del programa los alumnos de la clase regular obtuvieran resultados bastante peores en comparación de los de las otras clases (ya que vemos que hay un efecto incluso notable con la clase regular + ayuda que en el resto no se ve).

#### Modelos con más variables

Buscaremos añadir más variables para ver si puede mejorarse la variación observada en la variable dependiente (la suma de las puntuaciones de lectura y matemáticas). Además, se intenta de esta manera intengar mitigar o resolver posibles problemas en una asignación no totalmente aleatoria de los tratamientos.

A la vista de las variables con las que contamos, se añaden las siguientes como previsión de posible mejora. Estas cuentan con información de estudiante, profesorado y escuela:

- Género del estudiante (`Gender`)
- Etnicidad del estudiante (`Ethnicity_grouped`)
- Experiencia del maestro (`Experience`)
- Almuerzo gratuito (`Lunch`)
- Tipo de escuela (`School`)

Haremos distintos modelos incluyendo más o menos variables de las mostradas. Concretamente:

Modelo 1 (básico): $Y = \beta_0 + \beta_1 \cdot \text{SmallClass} + \beta_2 \cdot \text{RegularClassWithAide} + \epsilon$

Modelo 2: $Y = \beta_0 + \beta_1 \cdot \text{SmallClass} + \beta_2 \cdot \text{RegularClassWithAide} + \beta_3 \cdot \text{Experience} + \epsilon$

Modelo 3: $Y = \beta_0 + \beta_1 \cdot \text{SmallClass} + \beta_2 \cdot \text{RegularClassWithAide} + \beta_3 \cdot \text{Experience} + \beta_4 \cdot \text{School} \epsilon$


Modelo 4: 
\begin{equation}
\begin{aligned}
Y &= \beta_0 + \beta_1 \cdot \text{SmallClass} + \beta_2 \cdot \text{RegularClassWithAide} + \beta_3 \cdot \text{Experience} + \beta_4 \cdot \text{School} \\
&+ \beta_5 \cdot \text{Gender} + \beta_6 \cdot \text{Lunch} + \beta_7 \cdot \text{EthnicityGrouped} + \epsilon
\end{aligned}
\end{equation}

Modelo 5: 
\begin{equation}
\begin{aligned}
Y &= \beta_0 + \beta_1 \cdot \text{SmallClass} + \beta_2 \cdot \text{RegularClassWithAide} + \beta_3 \cdot \text{Experience} + \beta_4 \cdot \text{SchoolId} \\
&+ \beta_5 \cdot \text{Gender} + \beta_6 \cdot \text{Lunch} + \beta_7 \cdot \text{EthnicityGrouped} + \epsilon
\end{aligned}
\end{equation}


```{r mean-differences-advancedModels_k}
# Using just kindergarten data
starDf_k <- starDf %>%
  select(gender, ethnicity_grouped, stark, markK, lunchk, experiencek, schoolk, schoolidk)

model2k <- lm(markK ~ stark + experiencek, data = starDf_k)
model3k <- lm(markK ~ stark + experiencek + schoolk, data = starDf_k)
model4k <- lm(markK ~ stark + experiencek + schoolk + gender + lunchk + ethnicity_grouped, data = starDf_k)
model5k <- lm(markK ~ stark + experiencek + gender + lunchk + ethnicity_grouped + schoolidk, data = starDf_k)

rob_se_k <- list(sqrt(diag(vcovHC(basicModelk, type = "HC1"))),
                  sqrt(diag(vcovHC(model2k, type = "HC1"))),
                  sqrt(diag(vcovHC(model3k, type = "HC1"))),
                  sqrt(diag(vcovHC(model4k, type = "HC1"))),
                  sqrt(diag(vcovHC(model5k, type = "HC1")))
)
```


```{r mean-differences-summaryadvancedModels_k, include = F}
html_comparisonModels <- stargazer(
  basicModelk, model2k, model3k, model4k, model5k,
  title = capTab("Proyecto STAR: Estimación de diferencias: comparación entre modelos"),
  header = FALSE, 
  model.numbers = FALSE,
  omit = "schoolidk",  # Omitir schoolidk
  omit.labels = "Identificadores de escuela",
  omit.table.layout = "n",
  digits = 3, 
  type = "html",
  column.labels = c("Modelo 1", "Modelo 2", "Modelo 3", "Modelo 4", "Modelo 5"),
  dep.var.caption  = "Resultados para Kindergarten",
  dep.var.labels.include = FALSE,
  se = rob_se_k
)

# Quiero que el último "No" de table_html se reemplaze por un "Sí", solo el último de ellos.
html_comparisonModels <- gsub("No(?!.*No)", "Sí", html_comparisonModels, perl = TRUE)
# quitar primera lista
html_comparisonModels <- html_comparisonModels[2:length(html_comparisonModels)]
```

`r html_comparisonModels`

Las columnas de los Modelos 2 a 5 muestran que la inclusión de variables adicionales de índole estudiantil, docente y escolar no han modificado drásticamente el valor de la estimación del efecto del tratamiento.
Continuamos teniendo un valor positivo y significativo para el efecto de la clase pequeña en el rendimiento de los estudiantes, en contraposición al que otorga la ayuda en la clase regular que no es significativo. 

De todas maneras, estos resultados ayudan a fortalecer el hecho de que lo observado con el modelo básico no sufre demasiado de la posible asignación no aleatoria de los tratamientos. Añadir las variables de identificación aumenta considerablemente el valor del $R^2_\text{ajustado}$, disminuyendo además el valor de los errores estándar de los coeficientes que nos interesan (hay algo más de precisión, por tanto).














```{r}
# MarkK media según schoolId para kindergarten
starDf_k %>%
  group_by(schoolk) %>%
  summarise(meanMarkK = mean(markK, na.rm = TRUE)) %>%
  arrange(desc(meanMarkK))

# Graficalo
starDf_k %>%
  ggplot(aes(x = schoolk, y = markK)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de las puntuaciones de matemáticas y lectura en kindergarten",
       x = "schoolk", y = "markK")
```

```{r}
# MarkK media según schoolId para kindergarten
starDf_k %>%
  group_by(schoolidk) %>%
  summarise(meanMarkK = mean(markK, na.rm = TRUE)) %>%
  arrange(desc(meanMarkK))

# Graficalo con ggplot
starDf_k %>%
  ggplot(aes(x = schoolidk, y = markK)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribución de las puntuaciones de matemáticas y lectura en kindergarten",
       x = "schoolidk", y = "markK")
```



```{r}
# msot
```



