---
title: "Proyecto STAR"
subtitle: "Inferencia Causal"
description: "Máster en Ciencia de Datos (UV)"
author: "Adrián Lara, Jesús Martínez, Miguel Muñoz, Samuel Ortega & Pablo Vicente"
date: last-modified
date-format: "DD-MM-YYYY"
title-block-banner: "#B0C8D6"
format: 
  html:
    embed-resources: true
    smooth-scroll: true
    toc: true
    toc_float: yes
    theme: cosmo
    fontcolor: black
editor: source
execute: 
  echo: false
  warning: false
  error: false
  message: false
  include: true
lang: es
css: utilities/qmdStyle.css
bibliography: utilities/bibliography.bib
---


```{r setup}
#| include: false

# Cargar pacman
if (!require("pacman", quietly = TRUE)) {
  install.packages("pacman")
  library(pacman)
}

# Cargar los paquetes necesarios
p_load(AER, ggplot2, ggthemes, dplyr, tidyr, knitr, stargazer, sandwich, GGally, stringr, vcd, ggdag, kableExtra, reticulate)

# Ajustes adicionales
theme_set(
  theme_minimal() +
    theme(
      panel.border = element_rect(color = "black", fill = NA),
      axis.ticks = element_line(color = "black")))

defaultFillColor <- "steelblue"
update_geom_defaults("bar", aes(fill = defaultFillColor))
update_geom_defaults("boxplot", aes(fill = defaultFillColor))

# Definición de funciones
plotCombinedFeature <- function(starDf, featureId, featureLabel = NA, isNumeric = TRUE, removeNa = FALSE) {
  if (is.na(featureLabel)) {
    featureLabel <- featureId
  }
  plotDf <- pivot_longer(
    starDf,
    cols = grep(paste0("^", featureId, ".{1}$"), colnames(starDf), value = TRUE),
    names_to = "grade",
    values_to = "value")
  
  featureLevels <- paste0(featureId, c("k", "1", "2", "3"))
  plotDf$grade <- factor(
    plotDf$grade,
    levels = featureLevels,
    labels = c("Kindergarden", "Primero", "Segundo", "Tercero"),
    ordered = TRUE)
  
  if (removeNa) {
    plotDf <- na.omit(plotDf[, c("grade", "value")])
  }
  
  if (isNumeric) {
    ggplot(plotDf, aes(x = grade, y = value)) +
      geom_boxplot() +
      labs(x = "Curso", y = featureLabel)
  } else {
    ggplot(plotDf, aes(x = value, fill = grade)) +
      geom_bar(position = "dodge") +
      labs(x = featureLabel, y = "Frecuencia", fill = "Curso")
  }
}

# Numerización automática en tablas y figuras


capTabNo <- 2 
capFigNo <- 1

capTab <- function(x){
  x <- paste0("<strong>Tabla ", capTabNo,". </strong> ", x)
  capTabNo <<- capTabNo + 1
  x
}

capFig <- function(x, y){
  x <- paste0("<strong>Figura ", capFigNo, ".</strong> ", x, " \\label{fig:", y, "}")
  capFigNo <<- capFigNo + 1
  x
}
```

# Introducción

El proyecto *STAR* (*Student-Teacher Achievement Ratio*) es parte de un estudio sobre el tamaño de las clases llevado a cabo en Tennessee en tres fases (es la primera de las fases). Este estudio de Tennessee fue diseñado para determinar el efecto del **tamaño reducido de las clases** en los primeros grados sobre el **rendimiento académico** a corto y largo plazo de los alumnos. Se inspiró en un estudio prometedor realizado en Indiana sobre los beneficios de las clases pequeñas, pero también consideró los costos adicionales de más aulas y profesores. La legislatura de Tennessee autorizó este estudio de **cuatro años** para obtener datos sobre la eficacia de las clases reducidas.

Detallando en el propio proyecto *STAR*, se compararon los resultados de alumnos en **jardines de infancia** y en los **primeros tres grados**, en clases pequeñas de **13 a 17 alumnos**, clases regulares de **22 a 25 alumnos** y clases regulares con un **profesor particular**. Aproximadamente 6500 alumnos en 330 aulas de unas 80 escuelas fueron evaluados en **lectura**, **matemáticas** y habilidades básicas de estudio mediante [pruebas estandarizadas](https://en.wikipedia.org/wiki/Stanford_Achievement_Test_Series). Después de los cuatro años, se comprobó que las clases pequeñas mejoraron significativamente el aprendizaje temprano y los estudios cognitivos. En cualquier año de calendario, el experimento se llevó a cabo en solo uno de los grados, minimizando así el número de clases necesitadas.

```{r, groupsSTAR}
groupsTable <- data.frame(
  Grado = c("K", "1", "2", "3"),
  `Tratamiento 1` = c("Clase pequeña", "Clase pequeña", "Clase pequeña", "Clase pequeña"),
  `Tratamiento 2` = c("Clase regular + asistente", "Clase regular + asistente", "Clase regular + asistente", "Clase regular + asistente"),
  Control = c("Clase regular", "Clase regular", "Clase regular", "Clase regular")
)
kable(groupsTable, caption = "<strong>Tabla 1. </strong> Grupos de control y tratamiento en el experimento STAR")
```

Los datos del estudio están disponibles en el paquete `AER` de `R`.

# Descripción del problema

En primer lugar, cargamos los datos a nuestro espacio de trabajo.

```{r cargar-datos}
#| echo: true
data(STAR)
starDf <- STAR
```

Encontramos con las siguientes características:

1.  **gender**: Factor que indica el género del estudiante.

2.  **ethnicity**: Factor que indica la etnicidad del estudiante con niveles "cauc" (Caucásico), "afam" (Afroamericano), "asian" (Asiático), "hispanic" (Hispano), "amindian" (Indio Americano) o "other" (Otro).

3.  **birth**: Trimestre de nacimiento del estudiante (del año de clase).

4.  **stark**: Factor que indica el tipo de clase STAR en jardín de infancia: regular, pequeña o regular-con-ayudante. NA indica que no asistió a ninguna clase STAR.

5.  **star1**: Factor que indica el tipo de clase STAR en primer grado: regular, pequeña o regular-con-ayudante. NA indica que no asistió a ninguna clase STAR.

6.  **star2**: Factor que indica el tipo de clase STAR en segundo grado: regular, pequeña o regular-con-ayudante. NA indica que no asistió a ninguna clase STAR.

7.  **star3**: Factor que indica el tipo de clase STAR en tercer grado: regular, pequeña o regular-con-ayudante. NA indica que no asistió a ninguna clase STAR.

8.  **readk**: Puntuación total de lectura en jardín de infancia.

9.  **read1**: Puntuación total de lectura en primer grado.

10. **read2**: Puntuación total de lectura en segundo grado.

11. **read3**: Puntuación total de lectura en tercer grado.

12. **mathk**: Puntuación total de matemáticas en jardín de infancia.

13. **math1**: Puntuación total de matemáticas en primer grado.

14. **math2**: Puntuación total de matemáticas en segundo grado.

15. **math3**: Puntuación total de matemáticas en tercer grado.

16. **lunchk**: Factor que indica si el estudiante calificó para almuerzo gratuito en jardín de infancia.

17. **lunch1**: Factor que indica si el estudiante calificó para almuerzo gratuito en primer grado.

18. **lunch2**: Factor que indica si el estudiante calificó para almuerzo gratuito en segundo grado.

19. **lunch3**: Factor que indica si el estudiante calificó para almuerzo gratuito en tercer grado.

20. **schoolk**: Factor que indica el tipo de escuela en jardín de infancia: "inner-city" (ciudad interior), "suburban" (suburbana), "rural" (rural) o "urban" (urbana).

21. **school1**: Factor que indica el tipo de escuela en primer grado: "inner-city" (ciudad interior), "suburban" (suburbana), "rural" (rural) o "urban" (urbana).

22. **school2**: Factor que indica el tipo de escuela en segundo grado: "inner-city" (ciudad interior), "suburban" (suburbana), "rural" (rural) o "urban" (urbana).

23. **school3**: Factor que indica el tipo de escuela en tercer grado: "inner-city" (ciudad interior), "suburban" (suburbana), "rural" (rural) o "urban" (urbana).

24. **degreek**: Factor que indica el título más alto del maestro en jardín de infancia: "bachelor" (licenciatura), "master" (maestría), "specialist" (especialista) o "master+" (maestría+).

25. **degree1**: Factor que indica el título más alto del maestro en primer grado: "bachelor" (licenciatura), "master" (maestría), "specialist" (especialista) o "phd" (doctorado).

26. **degree2**: Factor que indica el título más alto del maestro en segundo grado: "bachelor" (licenciatura), "master" (maestría), "specialist" (especialista) o "phd" (doctorado).

27. **degree3**: Factor que indica el título más alto del maestro en tercer grado: "bachelor" (licenciatura), "master" (maestría), "specialist" (especialista) o "phd" (doctorado).

28. **ladderk**: Factor que indica el nivel de carrera del maestro en jardín de infancia: "level1" (nivel 1), "level2" (nivel 2), "level3" (nivel 3), "apprentice" (aprendiz), "probation" (en prueba) o "pending" (pendiente).

29. **ladder1**: Factor que indica el nivel de carrera del maestro en primer grado: "level1" (nivel 1), "level2" (nivel 2), "level3" (nivel 3), "apprentice" (aprendiz), "probation" (en prueba) o "noladder" (sin nivel).

30. **ladder2**: Factor que indica el nivel de carrera del maestro en segundo grado: "level1" (nivel 1), "level2" (nivel 2), "level3" (nivel 3), "apprentice" (aprendiz), "probation" (en prueba) o "noladder" (sin nivel).

31. **ladder3**: Factor que indica el nivel de carrera del maestro en tercer grado: "level1" (nivel 1), "level2" (nivel 2), "level3" (nivel 3), "apprentice" (aprendiz), "probation" (en prueba) o "noladder" (sin nivel).

32. **experiencek**: Años de experiencia total del maestro en jardín de infancia.

33. **experience1**: Años de experiencia total del maestro en primer grado.

34. **experience2**: Años de experiencia total del maestro en segundo grado.

35. **experience3**: Años de experiencia total del maestro en tercer grado.

36. **tethnicityk**: Factor que indica la etnicidad del maestro en jardín de infancia con niveles "cauc" (Caucásico) o "afam" (Afroamericano).

37. **tethnicity1**: Factor que indica la etnicidad del maestro en primer grado con niveles "cauc" (Caucásico) o "afam" (Afroamericano).

38. **tethnicity2**: Factor que indica la etnicidad del maestro en segundo grado con niveles "cauc" (Caucásico) o "afam" (Afroamericano).

39. **tethnicity3**: Factor que indica la etnicidad del maestro en tercer grado con niveles "cauc" (Caucásico), "afam" (Afroamericano) o "asian" (Asiático).

40. **systemk**: Factor que indica el ID del sistema escolar en jardín de infancia.

41. **system1**: Factor que indica el ID del sistema escolar en primer grado.

42. **system2**: Factor que indica el ID del sistema escolar en segundo grado.

43. **system3**: Factor que indica el ID del sistema escolar en tercer grado.

44. **schoolidk**: Factor que indica el ID de la escuela en jardín de infancia.

45. **schoolid1**: Factor que indica el ID de la escuela en primer grado.

46. **schoolid2**: Factor que indica el ID de la escuela en segundo grado.

47. **schoolid3**: Factor que indica el ID de la escuela en tercer grado.

## Análisis exploratorio de datos

Observamos que hay una gran cantidad de datos faltantes en la mayor parte de las variables.

```{r aed-na, fig.cap=capFig("Porcentaje de valores faltantes en las variables del conjunto de datos.", y = "aed-na")}
na_counts <- sapply(starDf, function(x) sum(is.na(x)))
total_counts <- nrow(starDf)

na_percentage <- (na_counts / total_counts) * 100

na_percentage_df <- data.frame(
  Column = names(na_percentage),
  NA_Percentage = as.numeric(na_percentage)
)

ggplot(na_percentage_df, aes(x = Column, y = NA_Percentage)) +
  geom_bar(stat = "identity") +
  labs(x = "Característica",
       y = "Porcentaje de NA (%)") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_y_continuous(labels = scales::percent_format(scale = 1))
```

Esto se debe a la naturaleza de los datos en el que se va a recoger información del estudiante en distintos cursos (que coinciden con los años del estudio). Así pues, encontraremos NAs en un estudiante que por ejemplo estuviese solo en el curso de 'Kindergarten' (jardín de infancia) en uno de las escuelas del estudio y luego se marchase a otras escuelas de fuera de estas (los NAs estarían aquí en los cursos 1st, 2nd, 3rd en todas las variables que eso implica).

Consideremos la primera observación del conjunto de datos:

```{r aed-na-ejemplo}
starDf[1, ]
```

En la salida encontramos que el estudiante ingresó al experimento en tercer grado en una clase regular, por lo que el tamaño de la clase se registra en star3 y las otras variables indicadoras de tipo de clase son `NA`. De la misma manera, sus puntuaciones de matemáticas y lectura para el tercer grado están disponibles; sin embargo, los valores de estas variables para otros grados no están presentes por la misma razón.

A modo de comprobación, nos aseguramos todas las entradas corresponden a estudiantes que participaron en el proyecto *STAR* al menos durante uno de los cuatro años.

```{r}
nAllStarsNA <- sum(rowSums(is.na(starDf[, c("stark", "star1", "star2", "star3")])) == 4)
cat("Número de entradas sin participaciones:", nAllStarsNA)
```

A continuación, analizamos las distribuciones de las variables descritas.

```{r aed-genero, fig.cap=capFig("Diagrama de barras del género de los estudiantes.", y = "aed-genero")}
ggplot(starDf, aes(x = gender)) +
  geom_bar() +
  labs(x = "Género", y = "Frecuencia acumulada")
```

```{r aed-etnicidad, fig.cap=capFig("Diagrama de barras de la etnicidad de los estudiantes.", y = "aed-etnicidad")}
ggplot(starDf, aes(x = ethnicity)) +
  geom_bar() +
  labs(x = "Etnicidad", y = "Frecuencia acumulada")
```

```{r aed-trim-nac, fig.cap=capFig("Diagrama de barras del trimestre de nacimiento de los estudiantes.", y = "aed-trim-nac")}
ggplot(starDf, aes(x = birth)) +
  geom_bar() +
  labs(x = "Trimestre de nacimiento", y = "Frecuencia acumulada")
```
```{r aed-star, fig.cap=capFig("Diagrama de barras del tipo de clase STAR de los estudiantes.", y = "aed-star")}
starDf %>%
  summarise(
    Kindergarden = sum(!is.na(stark)),
    Primero = sum(!is.na(star1)),
    Segundo = sum(!is.na(star2)),
    Tercero = sum(!is.na(star3))
  ) %>%
  pivot_longer(cols = everything(), names_to = "Curso", values_to = "Observaciones") %>%
  ggplot(aes(x = Curso, y = Observaciones, fill = Observaciones)) +
  geom_bar(stat = "identity") +
  labs(x = "Curso", y = "Número de observaciones", fill = "Número de observaciones") +
  scale_fill_gradient(low = "blue", high = "red")
```
Vemos de esta figura que el número de estudiantes no es constante a lo largo de los cursos. Naturalmente, esto no fue un experimento ideal. Podía haber movimiento estudiantil entre escuelas ajenas al experimento. A eso, ha de sumársele que en esos años no era obligatorio ir a `Kindergarten` en el estado de *Tennessee*, por lo que también mucha gente iniciaba su edación en `Primero`.


```{r aed-grupo, fig.cap=capFig("Diagrama de barras del grupo experimental de todos los cursos.", y = "aed-grupo")}
plotCombinedFeature(starDf, "star", "Grupo experimental", isNumeric = FALSE)
```

```{r aed-lectura, fig.cap=capFig("Boxplot de la puntuación de lectura de todos los cursos.", y = "aed-lectura")}
plotCombinedFeature(starDf, "read", "Puntuación de lectura")
```

```{r aed-mate, fig.cap=capFig("Boxplot de la puntuación de matemáticas de todos los cursos.", y = "aed-mate")}
plotCombinedFeature(starDf, "math", "Puntuación de matemáticas")
```

```{r aed-almuerzo, fig.cap=capFig("Diagrama de barras de la participación en el almuerzo gratuito de todos los cursos.", y = "aed-almuerzo")}
plotCombinedFeature(starDf, "lunch", "Almuerzo", isNumeric = FALSE)
```

```{r aed-tipo-escuela, fig.cap=capFig("Diagrama de barras del tipo de escuela de todos los cursos.", y = "aed-tipo-escuela")}
plotCombinedFeature(starDf, "school", "Tipo de escuela", isNumeric = FALSE)
```

```{r aed-titulo-maestro, fig.cap=capFig("Diagrama de barras del máximo título académico del maestro de todos los cursos.", y = "aed-titulo-maestro")}
plotCombinedFeature(starDf, "degree", "Título académico", isNumeric = FALSE)
```

```{r aed-nivel-carrera, fig.cap=capFig("Diagrama de barras del nivel de carrera del maestro de todos los cursos.", y = "aed-nivel-carrera")}
plotCombinedFeature(starDf, "ladder", "Nivel de carrera", isNumeric = FALSE)
```

```{r aed-exp, fig.cap=capFig("Boxplot de la experiencia del maestro de todos los cursos.", y = "aed-exp")}
plotCombinedFeature(starDf, "experience", "Experiencia del maestro (años)")
```

```{r aed-etnicidad-maestro, fig.cap=capFig("Diagrama de barras de la etnicidad del maestro de todos los cursos.", y = "aed-etnicidad-maestro")}
plotCombinedFeature(starDf, "tethnicity", "Etnicidad del maestro", isNumeric = FALSE)
```
Se observan distribuciones muy parecidas entre los distintos cursos.

```{r aed-id-escuela, fig.cap=capFig("Diagrama de barras de la etnicidad del maestro de todos los cursos.", y = "aed-id-escuela")}
plotCombinedFeature(starDf, "schoolid", "Identificador de escuela", isNumeric = FALSE, removeNa = TRUE)
```


```{r aed-school-ethnicity, fig.cap=capFig("Diagrama de barras de la etnicidad de los estudiantes por tipo de escuela.", y = "aed-school-ethnicity")}
starDf %>%
  pivot_longer(cols = c(schoolk, school1, school2, school3), 
               names_to = "curso", 
               values_to = "escuela") %>%
  drop_na(escuela, ethnicity) %>%
  ggplot(aes(x = escuela, fill = ethnicity)) +
  geom_bar(position = "dodge") +
  labs(title = "Distribución de la etnicidad por tipos de escuela en los distintos cursos",
       x = "Tipo de escuela",
       y = "Frecuencia",
       fill = "Etnicidad") +
  facet_wrap(~ curso, scales = "free_x") +
  theme_minimal()
```


Puede observarse cómo el tipo de escuela está muy relacionado con la etnicidad de los estudiantes. Esta clasificación en `inner-city`, `suburban`, `rural`, `urban` fue realizada por parte de los diseñadores del estudio, ya que los legisladores no habían definido los tipos. Se procedió de la siguiente manera:

Las `inner-city` y `suburban` se agrupaban en la categoría de *metropolitan* areas.

- `inner-city`: Las escuelas con esta clasificación están definidas como aquellas en las que más de la mitad de estudiantes recibían almuerzo gratuito.
- `suburban`: Las escuelas con esta clasificación son las que estaban en las áreas más externas de las ciudades metropolitanas.

En las áreas *no metropolitanas* las escuelas en ciudades con más de 2500 habitantes se clasificaban como `urban` y las escuelas en ciudades con menos de 2500 habitantes se clasificaban como `rural`.

```{r aed-school-lunch, fig.cap=capFig("Diagrama de barras de la participación en el almuerzo gratuito por tipo de escuela.", y = "aed-school-lunch")}
starDf %>%
  pivot_longer(cols = c(lunchk, lunch1, lunch2, lunch3), 
               names_to = "curso", 
               values_to = "almuerzo") %>%
  drop_na(almuerzo, ethnicity) %>%
  ggplot(aes(x = almuerzo, fill = ethnicity)) +
  geom_bar(position = "dodge") +
  labs(title = "Distribución de la etnicidad por tipos de almuerzo en los distintos cursos",
       x = "Tipo de almuerzo",
       y = "Frecuencia",
       fill = "Etnicidad") +
  facet_wrap(~ curso, scales = "free_x") +
  theme_minimal()
```
Puede verse claramente cómo los afroamericanos tenían mayor disposición a tener almuerzo gratuito. Esto seguramente se deba a su condición económica más vulnerable.

Observemos a continuación algunos mapas de correlaciones entre variables.

```{r birth_year_column_creation}
starDf <- starDf %>%
  mutate(
    year = as.numeric(str_extract(birth, "\\d{4}")),
    quarter = str_extract(birth, "Q\\d"),
    quarter_decimal = case_when(
      quarter == "Q1" ~ 0.25,
      quarter == "Q2" ~ 0.5,
      quarter == "Q3" ~ 0.75,
      quarter == "Q4" ~ 1
    ),
    birth_year = year + quarter_decimal
)
```


```{r correlation-map-students-k, message = FALSE, fig.cap = capFig("Mapa de correlaciones entre variables de puntuación, experiencia de profesorado y año + trimeste de nacimiento para Kindergarten.", y = "correlation-map-students")}
starDf %>%    
  select(readk, mathk, experiencek, birth_year) %>%
  ggpairs(
    lower = list(continuous = wrap("cor", method = "spearman", size = 3)),
    upper = list(continuous = wrap("cor", method = "pearson", size = 3))
  )
```


```{r correlation-map-students-1, message = FALSE, fig.cap = capFig("Mapa de correlaciones entre variables de puntuación, experiencia de profesorado y año + trimeste de nacimiento para 1st grade.", y = "correlation-map-students")}
starDf %>%
  select(read1, math1, experience1, birth_year) %>%
  ggpairs(
    lower = list(continuous = wrap("cor", method = "spearman", size = 3)),
    upper = list(continuous = wrap("cor", method = "pearson", size = 3))
  )
```


```{r correlation-map-students-2, message = FALSE, fig.cap = capFig("Mapa de correlaciones entre variables de puntuación, experiencia de profesorado y año + trimeste de nacimiento para 2nd grade.", y = "correlation-map-students")}
starDf %>%
  select(read2, math2, experience2, birth_year) %>%
  ggpairs(
    lower = list(continuous = wrap("cor", method = "spearman", size = 3)),
    upper = list(continuous = wrap("cor", method = "pearson", size = 3))
  )
```


```{r correlation-map-students-3, message = FALSE, fig.cap = capFig("Mapa de correlaciones entre variables de puntuación, experiencia de profesorado y año + trimeste de nacimiento para 3rd grade.", y = "correlation-map-students")}
starDf %>%
  select(read3, math3, experience3, birth_year) %>%
  ggpairs(
    lower = list(continuous = wrap("cor", method = "spearman", size = 3)),
    upper = list(continuous = wrap("cor", method = "pearson", size = 3))
  )
```

En la parte inferior izquierda aparecen las correlaciones de Pearson y en la superior derecha las de Spearman.

Como era de esperar, hay una correlación bastante notable entre las puntuaciones de lectura y matemáticas en todos los cursos. Quien es bueno en una materia, es bueno en la otra (estudia, vamos). El resto de correlaciones entre estas variables mostradas no suelen ser muy altas, aunque sí son en algunos casos significativamente distintas de 0. Por ejemplo, resulta curioso observar cómo hay cierta correlación negativa entre las puntuaciones y el `birth_year` en *KinderGarten* (quizás la diferencia de edad se note más en las edades tempranas). Ocurre lo contrario para el resto de cursos, habiendo una correlación positiva.

La experiencia del profesorado también tiene cierta correlación positiva con las puntuaciones, pero muy débil. $\\$

A continuación, analizamos posibles **asociaciones entre variables categóricas** para cada curso mediante el estadístico V de Cramer, que está acotado entre 0 y 1, siendo 1 asociación total entre un par de variables categóricas y 0 ninguna asociación. 

```{r cramer-v-functions}
# Función para calcular V de Cramer
cramer_v <- function(x, y) {
  tbl <- table(x, y, useNA = "no")
  chi2 <- chisq.test(tbl)$statistic
  n <- sum(tbl)
  min_dim <- min(dim(tbl)) - 1
  v <- sqrt(chi2 / (n * min_dim))
  return(v)
}

plot_cramer_heatmap <- function(data, var_names, title) {
  # Crear una matriz para almacenar los coeficientes V de Cramer
  n <- length(var_names)
  cramer_matrix <- matrix(NA, n, n, dimnames = list(var_names, var_names))
  
  # Calcular V de Cramer para cada par de variables categóricas
  for (i in 1:(n-1)) {
    for (j in (i+1):n) {
      cramer_matrix[i, j] <- cramer_v(data[[i]], data[[j]])
      cramer_matrix[j, i] <- cramer_matrix[i, j]
    }
  }
  
  # Convertir la matriz a un dataframe para ggplot2
  cramer_df <- as.data.frame(as.table(cramer_matrix))
  names(cramer_df) <- c("Var1", "Var2", "Cramer_V")
  
  # Crear el gráfico de mapa de calor
  heatmap <- ggplot(cramer_df, aes(Var1, Var2, fill = Cramer_V)) +
    geom_tile() +
    scale_fill_gradient(low = "white", high = "blue") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    labs(title = title,
         x = "Variable 1",
         y = "Variable 2",
         fill = "V de Cramer")
  
  return(heatmap)
}
```


```{r cramer-v-kindergarten, fig.cap=capFig("Coeficientes V de Cramer entre variables categóricas (Kindergarten).", y = "cramer-v-kindergarten")}
categorical_vars <- starDf[, c("stark", "gender", "lunchk", "schoolk", "degreek", "ladderk", "tethnicityk", "systemk")]
var_names <- colnames(categorical_vars)
plot_cramer_heatmap(categorical_vars, var_names, "Coeficientes V de Cramer entre variables categóricas (Kindergarten)")

```

```{r cramer-v-1st, fig.cap=capFig("Coeficientes V de Cramer entre variables categóricas (Primer curso).", y = "cramer-v-1st")}
categorical_vars <- starDf[, c("star1", "gender", "lunch1", "school1", "degree1", "ladder1", "tethnicity1", "system1")]
var_names <- colnames(categorical_vars)
plot_cramer_heatmap(categorical_vars, var_names, "Coeficientes V de Cramer entre variables categóricas (Primer curso)")
```

```{r cramer-v-2nd, fig.cap=capFig("Coeficientes V de Cramer entre variables categóricas (Segundo curso).", y = "cramer-v-2nd")}
categorical_vars <- starDf[, c("star2", "gender", "lunch2", "school2", "degree2", "ladder2", "tethnicity2", "system2")]
var_names <- colnames(categorical_vars)
plot_cramer_heatmap(categorical_vars, var_names, "Coeficientes V de Cramer entre variables categóricas (Segundo curso)")
```


```{r cramer-v-3rd, fig.cap=capFig("Coeficientes V de Cramer entre variables categóricas (Tercer curso).", y = "cramer-v-3rd")}
categorical_vars <- starDf[, c("star3", "gender", "lunch3", "school3", "degree3", "ladder3", "tethnicity3", "system3")]
var_names <- colnames(categorical_vars)
plot_cramer_heatmap(categorical_vars, var_names, "Coeficientes V de Cramer entre variables categóricas (Tercer curso)")
```

No se observa ninguna asociación fuerte entre el tratamiento y el resto de variables categóricas, lo cual está en concordancia con la asignación aleatoria del tratamiento. Donde sí observamos una mayor asociación es entre el tipo de escuela `school` y otras variables como `lunch`. Esto tiene sentido porque en el estudio se menciona que, la categoría de **schools** "inner-city" se asignó para las escuelas donde los alumnos recibían descuentos en la comida o comidas gratis (esto ya se había comentado anteriormente). 

La relación que aparece entre `technicity` y `school` se fundamenta en que colegios donde había mayor porcentaje **afam** también lo poseen en profesores (esto lo vemos en la próxima Figura, recordando que en **inner-city** había una gran cantidad de estudiantes con `ethnicity = "afam"`). La alta asociación entre **school** y **system** se explica porque debido a que escuelas del mismo tipo pueden pertenecer al mismo sistema escolar.


```{r aed-tethnicityk-schoolk, fig.cap=capFig("Diagrama de barras de la etnicidad del maestro por tipo de escuela en Kindergarten.", y = "aed-tethnicityk-schoolk")}
starDf %>%
  filter(!is.na(tethnicityk) & !is.na(schoolk)) %>%
  ggplot(aes(x = tethnicityk, fill = schoolk)) +
  geom_bar(position = "dodge") +
  labs(x = "Etnicidad del maestro", y = "Frecuencia", fill = "Tipo de escuela")
```

## Identificación del tratamiento

En el proyecto *STAR*, el tratamiento aplicado es la pertenencia a clases reducidas y a clases normales con ayuda, frente a clases normales sin ayuda. En este trabajo, convertimos este tratamiento en dos tratamientos binarios:

-   Clase reducida frente a clase normal
-   Clase normal con ayuda frente a clase normal sin ayuda

Por otra parte, escogemos como efecto la variación de una nueva variable **mark**, definida como la suma de las puntuaciones en lectura y matemáticas, habitual en la literatura relacionada con este estudio.

Además, realizamos el análisis para cada año de manera independiente.

## Distribuciones de variables por tratamiento

Pasemos a ver las distribuciones de algunas variables que consideramos de interés en función del tratamiento, con el objetivo de ver si hay una asignación aleatoria de los tratamientos y trabajamos con la hipótesis de independencia.

```{r gender-by-treatment, fig.cap=capFig("Diagrama de barras del género de los estudiantes por tratamiento.", y = "gender-by-treatment")}
starDf %>%
  filter(!is.na(stark) & !is.na(gender) & !is.na(star1) & !is.na(star2) & !is.na(star3)) %>%
  pivot_longer(cols = c(stark, star1, star2, star3), names_to = "treatment", values_to = "value") %>%
  ggplot(aes(x = gender, fill = value)) +
  geom_bar(position = "dodge") +
  labs(x = "Género", y = "Frecuencia", fill = "Tratamiento") +
  facet_wrap(~treatment) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Vemos que las distribuciones de género son muy similares para los distintos tratamientos.


```{r ethnicity-by-treatment, fig.cap=capFig("Diagrama de barras de la etnicidad de los estudiantes por tratamiento", y = "ethnicity-by-treatment")}
# Agrupar ethnicity en cauc, afam y other
starDf$ethnicity_grouped <- ifelse(starDf$ethnicity == "cauc", "cauc", "afam + other")

starDf %>%
  mutate(ethnicity_grouped = ifelse(ethnicity == "cauc", "cauc", "afam + other")) %>%
  filter(!is.na(stark) & !is.na(ethnicity_grouped) & !is.na(star1) & !is.na(star2) & !is.na(star3)) %>%
  pivot_longer(cols = c(stark, star1, star2, star3), names_to = "treatment", values_to = "value") %>%
  ggplot(aes(x = ethnicity_grouped, fill = value)) +
  geom_bar(position = "dodge") +
  labs(x = "Etnicidad (agrupada)", y = "Frecuencia", fill = "Tratamiento") +
  facet_wrap(~treatment) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

En la nueva variable `ethnicity_grouped` las distribuciones también son similares.


```{r experience-by-treatment, fig.cap=capFig("Boxplot de la experiencia del maestro por tratamiento.", y = "experience-by-treatment")}
starDf %>%
  filter(!is.na(stark) & !is.na(experiencek) & !is.na(star1) & !is.na(star2) & !is.na(star3)) %>%
  pivot_longer(cols = c(stark, star1, star2, star3), names_to = "treatment", values_to = "value") %>%
  ggplot(aes(x = experiencek, fill = value)) +
  geom_density(alpha = 0.5) +  # Utilizamos geom_density para una distribución más suave
  labs(x = "Experiencia (años)", y = "Densidad", fill = "Tratamiento") +
  facet_wrap(~treatment) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

En este caso observamos una diferencia apreciable: la experiencia de los maestros en las clases reducidas suele ser menor.

```{r school-by-treatment, fig.cap=capFig("Diagrama de barras del tipo de escuela por tratamiento.", y = "school-by-treatment")}
starDf %>%
  filter(!is.na(stark) & !is.na(star1) & !is.na(star2) & !is.na(star3)) %>%
  pivot_longer(cols = c(stark, star1, star2, star3), names_to = "treatment", values_to = "value") %>%
  ggplot(aes(x = schoolk, fill = value)) +
  geom_bar(position = "dodge") +
  labs(x = "Tipo de escuela", y = "Frecuencia", fill = "Tratamiento") +
  facet_wrap(~treatment) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Las distribuciones de tipo de escuela según los distintos tratamientos también son de un vistazo bastante similares.

## Selección de variables confusoras: creación del modelo DAG

El modelo causal que se mostrará a continuación es el que ha dado menos problemas a la hora de recuperar efectos del tratamiento en etapas posteriores (sobre todo en la parte de DoubleML). Son también las variables sobre las que más hincapié se hace en la literatura que hemos consultado [@hanck2021introduction; @Mosteller].

Estas variables son:

-   Género del estudiante (`gender`)
-   Experiencia del profesorado (`experience`)
-   Etnicidad del estudiante (`ethnicity`)
-   Participación en el almuerzo gratuito (`lunch`)
-   Tipo de escuela (`school`)

La variable `schoolid` veremos posteriormente que otorga mucha de la variabilidad explicada en un modelo de regresión múltiple, pero nos daba severos problemas en estimaciones de ATE con otro tipo de modelo y por ello no la incluimos en el modelo DAG. Al resto de variables como `tethnicity`, `degree` o `ladder` les sucedía algo parecido, pero en este caso tampoco aportaban tanto a la variabilidad explicada en el modelo de regresión.


```{r DAGmodel, fig.cap=capFig("Modelo DAG para la recuperación del efecto del tratamiento.", y = "DAGmodel")}
dag <- dagify(
  mark ~ star + gender + experience + ethnnicity + lunch + school,
  star ~ gender + experience + ethnnicity + lunch + school,
  exposure = "star", 
  outcome = "mark"
)

dag_data <- tidy_dagitty(dag) %>%
  mutate(color = case_when(
    name == "star" ~ "blue",
    name == "mark" ~ "green"
  ))

ggdag(dag_data) +
  geom_dag_edges() + 
  geom_dag_node(aes(color = color), size = 15) + 
  theme_dag_blank() + #
  scale_color_identity() + 
  labs(title = "Diagrama Acíclico Dirigido (DAG)",
       subtitle = "Mecanismo Generador de Datos") +
  theme(plot.title = element_text(size = 16, face = "bold"),
        plot.subtitle = element_text(size = 12),
        plot.caption = element_text(size = 10)) +
  geom_dag_text(aes(label = name), size = 4, color = "red") 

```

# Análisis del efecto del tratamiento

Crearemos en primer lugar una nueva variable que sea la suma de las puntuaciones de lectura y matemáticas para cada curso (el `mark` mostrado anteriormente en el DAG). Además, calcularemos el percentil de esta variable (`markPerc`).

```{r mark-variables}
#convertir_a_cuartiles <- function(datos) {
#  cuartiles <- quantile(datos, probs = seq(0, 1, by = 0.01), na.rm = TRUE)
#  cuartiles <- unique(cuartiles)
  
  # Si hay menos de 5 límites únicos, añadir una pequeña cantidad para hacerlos únicos
#  if (length(cuartiles) < 5) {
#    cuartiles <- sort(unique(c(cuartiles, cuartiles + 1e-10 * (1:length(cuartiles)))))
#  }
  
#  as.numeric(cut(datos, breaks = cuartiles, include.lowest = TRUE))
#}

starDf$markK <- starDf$readk + starDf$mathk
starDf$mark1 <- starDf$read1 + starDf$math1
starDf$mark2 <- starDf$read2 + starDf$math2
starDf$mark3 <- starDf$read3 + starDf$math3

# Convertir las puntuaciones a índices de percentiles usando convertir_a_cuartiles
#starDf$markPerck <- convertir_a_cuartiles(starDf$markK)
#starDf$markPerc1 <- convertir_a_cuartiles(starDf$mark1)
#starDf$markPerc2 <- convertir_a_cuartiles(starDf$mark2)
#starDf$markPerc3 <- convertir_a_cuartiles(starDf$mark3)

# Convertir las puntuaciones a índices de percentiles usando ecdf (empirical cumulative distribution function)

starDf$markPerck <- round(ecdf(starDf$markK)(starDf$markK) * 100, 1)
starDf$markPerc1 <- round(ecdf(starDf$mark1)(starDf$mark1) * 100, 1)
starDf$markPerc2 <- round(ecdf(starDf$mark2)(starDf$mark2) * 100, 1)
starDf$markPerc3 <- round(ecdf(starDf$mark3)(starDf$mark3) * 100, 1)
```


## Estimación naive del efecto del tratamiento

Para obtener una primera estimación del efecto medio del tratamiento (ATE) para cada curso podemos emplear el estimador diferencia en medias (DIM), definido como el valor promedio de la respuesta de los tratados menos el valor promedio de la respuesta para los no tratados. En ausencia de independencia, independencia condicional o asigación aleatoria del tratamiento, este es un estimador sesgado y es distinto al efecto medio del tratamiento.

Según la documentación del estudio, tanto la asignación de alumnos como de profesores fue totalmente aleatoria, por lo que podemos tomar el DIM como una primera estimación válida del ATE con la que comparar el resto de estimaciones que realizaremos más adelante.

```{r mean-differences-naive}
small_regular_k <- round(mean(starDf$markK[starDf$stark == "small"], na.rm = TRUE) - mean(starDf$markK[starDf$stark == "regular"], na.rm = TRUE), 3)
small_regular_1 <- round(mean(starDf$mark1[starDf$star1 == "small"], na.rm = TRUE) - mean(starDf$mark1[starDf$star1 == "regular"], na.rm = TRUE), 3)
small_regular_2 <- round(mean(starDf$mark2[starDf$star2 == "small"], na.rm = TRUE) - mean(starDf$mark2[starDf$star2 == "regular"], na.rm = TRUE), 3)
small_regular_3 <- round(mean(starDf$mark3[starDf$star3 == "small"], na.rm = TRUE) - mean(starDf$mark3[starDf$star3 == "regular"], na.rm = TRUE), 3)
regularAide_regular_k <- round(mean(starDf$markK[starDf$stark == "regular+aide"], na.rm = TRUE) - mean(starDf$markK[starDf$stark == "regular"], na.rm = TRUE), 3)
regularAide_regular_1 <- round(mean(starDf$mark1[starDf$star1 == "regular+aide"], na.rm = TRUE) - mean(starDf$mark1[starDf$star1 == "regular"], na.rm = TRUE), 3)
regularAide_regular_2 <- round(mean(starDf$mark2[starDf$star2 == "regular+aide"], na.rm = TRUE) - mean(starDf$mark2[starDf$star2 == "regular"], na.rm = TRUE), 3)
regularAide_regular_3 <- round(mean(starDf$mark3[starDf$star3 == "regular+aide"], na.rm = TRUE) - mean(starDf$mark3[starDf$star3 == "regular"], na.rm = TRUE), 3)

naiveEstimates <- rbind(c(small_regular_k, small_regular_1, small_regular_2, small_regular_3),
                        c(regularAide_regular_k, regularAide_regular_1, regularAide_regular_2, regularAide_regular_3))

rownames(naiveEstimates) <- c("Small - Regular", "Regular+Aide - Regular")
colnames(naiveEstimates) <- c("K", "1", "2", "3")

kable(naiveEstimates, caption = capTab("Estimaciones naive del efecto del tratamiento para los diferentes cursos"))
```

Estos resultados son exactamente los mismos que los que se mostrarán a continuación con el modelo básico de regresión lineal. Sin embargo, lo siguiente será más riguroso al incluir también estimaciones del error y cuestiones de significancia.

## Modelos de regresión

### Modelo básico

Consideramos el modelo:

$Y = \beta_0 + \beta_1 \cdot \text{SmallClass} + \beta_2 \cdot \text{RegularClassWithAide} + \epsilon$

donde $Y$ es la variable respuesta que nos será de interés, $\beta_0$ es el intercepto, $\beta_1$ es el indicador de la clase pequeña, $\beta_2$ es el indicador de la clase regular con ayuda. $\epsilon$ es el término de ruido usual incorporado en el modelo.

Se toma en primer lugar a $Y = \text{mark}$, la suma de las puntuaciones de lectura y matemáticas (`read` + `math`).

Se calculan a continuación modelos lineales de regresión siguiendo la expresión anterior para cada uno de los cursos. Se calcularán también los errores estándar robustos para cada uno de los coeficientes (uso de la función `vcovHC` que contiene la matriz de covarianza robusta de los coeficientes estimados). Estos se utilizan para corregir los problemas de heterocedasticidad (cuando la varianza de los errores no es constante) en los modelos de regresión.


```{r mean-differences-basicModel}
basicModelk <- lm(markK ~ stark, data = starDf)
basicModel1 <- lm(mark1 ~ star1, data = starDf)
basicModel2 <- lm(mark2 ~ star2, data = starDf)
basicModel3 <- lm(mark3 ~ star3, data = starDf)

rob_se_basic <- list(sqrt(diag(vcovHC(basicModelk, type = "HC1"))),
                 sqrt(diag(vcovHC(basicModel1, type = "HC1"))),
                 sqrt(diag(vcovHC(basicModel2, type = "HC1"))),
                 sqrt(diag(vcovHC(basicModel3, type = "HC1"))))
```

```{r mean-differences-summarybasicModel, include = FALSE}
html_basicModel <- stargazer(basicModelk, basicModel1, basicModel2, basicModel3,
  title = capTab("Estimación de diferencias entre cursos: modelo básico"),
  header = FALSE, 
  model.numbers = F,
  omit.table.layout = "n",
  digits = 3, 
  type = "html",
  column.labels = c("K", "1", "2", "3"),
  dep.var.caption  = "Variable dependiente: Curso",
  dep.var.labels.include = FALSE,
  se = rob_se_basic)

# quitar primer lista de la tabla esta
html_basicModel <- html_basicModel[2:length(html_basicModel)]

# Concatenar todo el html para no tener una lista de strings
html_basicModel <- paste(html_basicModel, collapse = "")
```

`r html_basicModel`


Los resultados de la Tabla anterior dejan claro que hay un incremento del rendimiento del estudiante cuando está en clases reducidas (ver valores de los coeficientes, que además son muy significativos '***'). Las estimaciones están entre 13.899 y 29.781, si bien es cierto que el efecto en el curso 1 se separa un poco de los demás. Esto podría deberse a que en ese año en particular los resultados de la case regular fueron bastante peores en comparación de los de las otras clases (ya que vemos que hay un efecto incluso notable con la clase regular + ayuda que en el resto no se ve).

### Modelos con más variables

Buscaremos añadir más variables para ver si puede mejorarse la variación observada en la variable dependiente (la suma de las puntuaciones de lectura y matemáticas). Además, se intenta de esta manera intengar mitigar o resolver posibles problemas en una asignación no totalmente aleatoria de los tratamientos.

Se añaden las variables comentadas anteriormente en el DAG, así como la variable `schoolId` que aumenta mucho el valor de la variabilidad explicada. Los modelos son los siguientes:

Haremos distintos modelos incluyendo más o menos variables de las mostradas. Concretamente:

Modelo 1 (básico): $Y = \beta_0 + \beta_1 \cdot \text{SmallClass} + \beta_2 \cdot \text{RegularClassWithAide} + \epsilon$

Modelo 2: $Y = \beta_0 + \beta_1 \cdot \text{SmallClass} + \beta_2 \cdot \text{RegularClassWithAide} + \beta_3 \cdot \text{Experience} + \epsilon$

Modelo 3: $Y = \beta_0 + \beta_1 \cdot \text{SmallClass} + \beta_2 \cdot \text{RegularClassWithAide} + \beta_3 \cdot \text{Experience} + \beta_4 \cdot \text{School} \epsilon$


Modelo 4 (el del DAG): 
\begin{equation}
\begin{aligned}
Y &= \beta_0 + \beta_1 \cdot \text{SmallClass} + \beta_2 \cdot \text{RegularClassWithAide} + \beta_3 \cdot \text{Experience} + \beta_4 \cdot \text{School} \\
&+ \beta_5 \cdot \text{Gender} + \beta_6 \cdot \text{Lunch} + \beta_7 \cdot \text{EthnicityGrouped} + \epsilon
\end{aligned}
\end{equation}

Modelo 5: 
\begin{equation}
\begin{aligned}
Y &= \beta_0 + \beta_1 \cdot \text{SmallClass} + \beta_2 \cdot \text{RegularClassWithAide} + \beta_3 \cdot \text{Experience} + \beta_4 \cdot \text{SchoolId} \\
&+ \epsilon
\end{aligned}
\end{equation}

Modelo 6: 
\begin{equation}
\begin{aligned}
Y &= \beta_0 + \beta_1 \cdot \text{SmallClass} + \beta_2 \cdot \text{RegularClassWithAide} + \beta_3 \cdot \text{Experience} + \beta_4 \cdot \text{SchoolId} \\
&+ \beta_5 \cdot \text{Gender} + \beta_6 \cdot \text{Lunch} + \beta_7 \cdot \text{EthnicityGrouped} + \epsilon
\end{aligned}
\end{equation}

Se presentan los resultados solo para el curso de jardín de infancia en aras de la brevedad. Los resultados para los otros cursos son similares.

```{r mean-differences-advancedModels_k}
# Using just kindergarten data
starDf_k <- starDf %>%
  select(gender, ethnicity_grouped, stark, markK, lunchk, experiencek, schoolk, schoolidk, markPerck, tethnicityk)  # tethnicity hard to be used

model2k <- lm(markK ~ stark + experiencek, data = starDf_k)
model3k <- lm(markK ~ stark + experiencek + schoolk, data = starDf_k)
model4k <- lm(markK ~ stark + experiencek + schoolk + gender + lunchk + ethnicity_grouped, data = starDf_k)
model5k <- lm(markK ~ stark + experiencek + schoolidk, data = starDf_k)
model6k <- lm(markK ~ stark + experiencek + gender + lunchk + ethnicity_grouped + schoolidk, data = starDf_k)

rob_se_k <- list(sqrt(diag(vcovHC(basicModelk, type = "HC1"))),
                  sqrt(diag(vcovHC(model2k, type = "HC1"))),
                  sqrt(diag(vcovHC(model3k, type = "HC1"))),
                  sqrt(diag(vcovHC(model4k, type = "HC1"))),
                  sqrt(diag(vcovHC(model5k, type = "HC1"))),
                  sqrt(diag(vcovHC(model6k, type = "HC1")))
)
```


```{r mean-differences-summaryadvancedModels_k, include = F}
html_comparisonModels <- stargazer(
  basicModelk, model2k, model3k, model4k, model5k, model6k,
  title = capTab("Estimación de diferencias: comparación entre modelos para Kindergarten"),
  header = FALSE, 
  model.numbers = FALSE,
  omit = "schoolidk",  # Omitir schoolidk
  omit.labels = "Identificadores de escuela",
  omit.table.layout = "n",
  digits = 3, 
  type = "html",
  column.labels = c("Modelo 1", "Modelo 2", "Modelo 3", "Modelo 4 (DAG)", "Modelo 5", "Modelo 6"),
  dep.var.caption  = "Resultados para Kindergarten",
  dep.var.labels.include = FALSE,
  se = rob_se_k
)

# Replace last "no", by "yes"
html_comparisonModels[length(html_comparisonModels)] <- gsub("no", "yes", html_comparisonModels[length(html_comparisonModels)])


html_comparisonModels <- gsub("No(?!.*No)", "Sí", html_comparisonModels, perl = TRUE)
html_comparisonModels <- gsub("No(?!.*No)", "Sí", html_comparisonModels, perl = TRUE)

html_comparisonModels <- html_comparisonModels[2:length(html_comparisonModels)]

html_comparisonModels <- paste(html_comparisonModels, collapse = "")
```

`r html_comparisonModels`

Las columnas de los Modelos 2 a 6 muestran que la inclusión de variables adicionales de índole estudiantil, docente y escolar no han modificado drásticamente el valor de la estimación del efecto del tratamiento.
Continuamos teniendo un valor positivo y significativo para el efecto de la clase pequeña en el rendimiento de los estudiantes, en contraposición al que otorga la ayuda en la clase regular que no es significativo. 

De todas maneras, estos resultados ayudan a fortalecer el hecho de que lo observado con el modelo básico no sufre demasiado de la posible asignación no aleatoria de los tratamientos. Añadir las variables de identificación aumenta considerablemente el valor del $R^2_\text{ajustado}$, disminuyendo además el valor de los errores estándar de los coeficientes que nos interesan (hay algo más de precisión, por tanto).

Fijando los efectos que nos ofrecen los identificadores de escuela el efecto de la experiencia del profesorado sale a la luz (modelo número 5). Se observa que cada año de experiencia otorga 0.74 puntos más en la suma de las puntuaciones de lectura y matemáticas.

Todos estos valores cuantitativos de incremento en la nota resultarían útiles si estuviéramos acostumbrados con el sistema de puntuaciones. Sin embargo, como no es el caso, lo mejor es hacer una comparación en términos de desviaciones estándar o bien de incremento de percentiles.

```{r mean-differences-summary-adapted}
# desviaciones estandar muestrales de las notas según el tratamiento en los distintos cursos / años
SSD <- c("K" = sd(na.omit(starDf$markK)),
         "1" = sd(na.omit(starDf$mark1)),
         "2" = sd(na.omit(starDf$mark2)),
         "3" = sd(na.omit(starDf$mark3)))



# traducción de resultados normalizando por desviaciones estándar muestrales

# Valores de estimación de efecto
Small <- c("K" = as.numeric(coef(basicModelk)[2]/SSD[1]),
           "1" = as.numeric(coef(basicModel1)[2]/SSD[2]),
           "2" = as.numeric(coef(basicModel2)[2]/SSD[3]),
           "3" = as.numeric(coef(basicModel3)[2]/SSD[4]))

# Errores estándar de los coeficientes estimados
SmallSE <- c("K" = as.numeric(rob_se_basic[[1]][2]/SSD[1]),
             "1" = as.numeric(rob_se_basic[[2]][2]/SSD[2]),
             "2" = as.numeric(rob_se_basic[[3]][2]/SSD[3]),
             "3" = as.numeric(rob_se_basic[[4]][2]/SSD[4]))

# Valores de estimación de efecto
RegAide<- c("K" = as.numeric(coef(basicModelk)[3]/SSD[1]),
            "1" = as.numeric(coef(basicModel1)[3]/SSD[2]),
            "2" = as.numeric(coef(basicModel2)[3]/SSD[3]),
            "3" = as.numeric(coef(basicModel3)[3]/SSD[4]))

# Errores estándar de los coeficientes estimados
RegAideSE <- c("K" = as.numeric(rob_se_basic[[1]][3]/SSD[1]),
               "1" = as.numeric(rob_se_basic[[2]][3]/SSD[2]),
               "2" = as.numeric(rob_se_basic[[3]][3]/SSD[3]),
               "3" = as.numeric(rob_se_basic[[4]][3]/SSD[4]))

summaryBasicModel <- t(round(data.frame(
                        Small, SmallSE, RegAide, RegAideSE, SSD),
                        digits =  3))
```

```{r mean-differences-summary-adapted-tab}
kable(summaryBasicModel, caption = capTab("Estimaciones de efecto del tratamiento normalizadas por desviación estándar muestral para Kindergarten: modelo básico"))
```

SSD es la desviación estándar muestral de la variable `mark` para cada curso. Los valores de `Small` y `RegAide` son los incrementos en la nota normalizados por la desviación estándar muestral. Los valores de `SmallSE` y `RegAideSE` son los errores estándar de los coeficientes estimados normalizados por la desviación estándar muestral.


La diferencia que otorga estar en la clase reducida está en torno al 0.2 de desviación estándar en incremento de rendimiento, a excepción de lo ocurrido en el curso 1, por lo comentado anteriormente.

```{r dfSaving}
# Guardar starDf como csv para luego cargarlo en Python. Si no existe la carpeta data, crearla
if (!dir.exists("data")) {
  dir.create("data")
}

write.csv(starDf, "data/starDf.csv", row.names = FALSE)
```

## Uso de Meta-Learners

Los meta-learners se basan en utilización de métodos ML disponibles diseñados para tareas de regresión o clasificación (no modificados para inferencia causal). Los meta-learners son una manera sencilla de aprovechar los métodos predictivos ML para estimar efectos condicionales. Se agrupan a su vez en métodos para la predicción de la respuesta condicional (S- y T-learner) o aquellos además usan una estimación del *Propensity Score* (p.e. DR- y X-learner).

Se utiliza la librería `econml` [@econml].


```{python libraryLoading}
# importamos metalearners
from econml.metalearners import TLearner, SLearner, XLearner
from econml.dr import DRLearner

#  importamos librerias auxiliares
import numpy as np
from numpy.random import binomial, multivariate_normal, normal, uniform
from sklearn import linear_model
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor
import matplotlib.pyplot as plt
import pandas as pd
import statsmodels.api as sm
import statsmodels.formula.api as smf

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Lasso
from sklearn.linear_model import Ridge
from sklearn.pipeline import make_pipeline
import os
#import rpy2.robjects as robjects

import shap
```

```{python python-fuctions}
def capTabpy(x):
    global capTabNo
    capTabNo += 1
    fstring = "<strong>Tabla {}. </strong> {}".format(capTabNo, x)
    string = str(fstring)
    return string

def capFigpy(x, y):
    global capFigNo
    capFigNo += 1
    fstring = "<strong>Figura {}. </strong> {} \\label{{fig:{}}}".format(capFigNo, x, y)
    string = str(fstring)
    return string
```

```{python}
capTabNo = 5
capFigNo = 31
```

```{python}
# Crear directorio de images si no existe
if not os.path.exists("./images"):
    os.makedirs("./images")
```

```{python seed}
seed = 666
```

```{python dfLoading}
starDf = pd.read_csv("./data/starDf.csv")
```

Para la inclusión en los diferentes modelos necesitamos tener las cosas bien preprocesadas, ya que los metalearners solo admiten variables que sean numéricas. Se transformarán las variables categóricas a variables *dummy* y se eliminarán las filas con valores faltantes cuando sea necesario. Un ejemplo del conjunto de datos que tenemos se muestra a continuación. Puede observarse que nos hemos quedado con las variables del modelo DAG que dijimos con anterioridad.

Una cosa relevante de mencionar es que a partir de aquí *nos hemos centrado en evaluar solo el tratamiento de la clase pequeña frente a la clase regular*, ya que se ha visto anteriormente que entre la clase regular y la clase regular con ayuda no parecía haber diferencias significativas.


```{python dfPreprocessing}
def preprocess_data(df, star_column, experience_column, school_column, lunch_column, ethnicity_column, mark_column):# schoolid_column, tethnicity_column
    
    # Seleccionar columnas relevantes y eliminar filas con valores faltantes
    df_processed = df[[star_column, experience_column, school_column, 'gender', lunch_column, ethnicity_column, mark_column]].dropna() # schoolid_column, tethnicity_column
    
    # Filtrar las filas donde el valor de la columna star no sea 'regular+aide'
    df_processed = df_processed[df_processed[star_column] != 'regular+aide']
    
    # Convertir la columna 'star' en variable binaria (1 para 'small', 0 para otro valor)
    df_processed[star_column] = df_processed[star_column].apply(lambda x: 1 if x == 'small' else 0)
    
    # Convertir la columna 'gender' en variable binaria (1 para 'female', 0 para otro valor)
    df_processed['gender'] = df_processed['gender'].apply(lambda x: 1 if x == 'female' else 0)
    
    # Convertir la columna 'lunch' en variable binaria (1 para 'free', 0 para otro valor)
    df_processed[lunch_column] = df_processed[lunch_column].apply(lambda x: 1 if x == 'free' else 0)
    
    # Convertir la columna 'ethnicity_grouped' en variable binaria (1 para 'cauc', 0 para otro valor)
    df_processed[ethnicity_column] = df_processed[ethnicity_column].apply(lambda x: 1 if x == 'cauc' else 0)
    
    # Eliminar filas con NA en la columna schoolid_column
    #df_processed = df_processed.dropna(subset=[schoolid_column])
    
    # Agrupar la techniticy_column en cauc con 1 y 0 el resto
    #df_processed[tethnicity_column] = df_processed[tethnicity_column].apply(lambda x: 1 if x == 'cauc' else 0)
    
    # Obtener variables dummy para la columna school_column
    df_processed = pd.get_dummies(df_processed, columns=[school_column])
    
    # Convertir todas las columnas a tipo float
    df_processed = df_processed.astype(float)
    
    return df_processed
```

```{python dfPreprocessingCalls}
starDf_k = preprocess_data(starDf, "stark", "experiencek", "schoolk", "lunchk", "ethnicity_grouped", "markK") # tethnicityk, schoolidk no se mete puesto que mete mucho error
starDf_1 = preprocess_data(starDf, "star1", "experience1", "school1", "lunch1", "ethnicity_grouped", "mark1")
starDf_2 = preprocess_data(starDf, "star2", "experience2", "school2", "lunch2", "ethnicity_grouped", "mark2")
starDf_3 = preprocess_data(starDf, "star3", "experience3", "school3", "lunch3", "ethnicity_grouped", "mark3")
```

```{python showingExample}
# Mostrar 5 primeras filas
starDf_k.head()
```

```{python dfSplittingforModels}
Yk = starDf_k["markK"].values
Xk = starDf_k.drop(columns=["markK", "stark"])
Tk = starDf_k["stark"].values

Y1 = starDf_1["mark1"].values
X1 = starDf_1.drop(columns=["mark1", "star1"])
T1 = starDf_1["star1"].values

Y2 = starDf_2["mark2"].values
X2 = starDf_2.drop(columns=["mark2", "star2"])
T2 = starDf_2["star2"].values

Y3 = starDf_3["mark3"].values
X3 = starDf_3.drop(columns=["mark3", "star3"])
T3 = starDf_3["star3"].values
```


Dividimos el conjunto de datos en train y test. Se ha optado por una división 80 - 20. Se ha fijado una semilla para que los resultados sean reproducibles.

```{python trainTestSplit, echo = TRUE}
xTrain_k, xTest_k, tTrain_k, tTest_k, yTrain_k, yTest_k = train_test_split(Xk, Tk, Yk, test_size=0.2, random_state=seed)
xTrain_1, xTest_1, tTrain_1, tTest_1, yTrain_1, yTest_1 = train_test_split(X1, T1, Y1, test_size=0.2, random_state=seed)
xTrain_2, xTest_2, tTrain_2, tTest_2, yTrain_2, yTest_2 = train_test_split(X2, T2, Y2, test_size=0.2, random_state=seed)
xTrain_3, xTest_3, tTrain_3, tTest_3, yTrain_3, yTest_3 = train_test_split(X3, T3, Y3, test_size=0.2, random_state=seed)
```

Se muestra a continuación lo que sería la distribución de la respuesta (`mark`) por estatus de tratamiento para el curso de *Kindergarten*.


```{python hist-respuesta-tratamiento, fig.cap="<strong>Figura 32. </strong> Distribución de la respuesta por estatus de tratamiento (clase regular vs clase reducida) en KinderGarten.", echo=FALSE, message = FALSE, include = FALSE}

# Agrupar los datos por tratamiento
y0_k = Yk[Tk == 0]
y1_k = Yk[Tk == 1]
respuesta_k = [y0_k, y1_k]

y0_1 = Y1[T1 == 0]
y1_1 = Y1[T1 == 1]
respuesta_1 = [y0_1, y1_1]

y0_2 = Y2[T2 == 0]
y1_2 = Y2[T2 == 1]
respuesta_2 = [y0_2, y1_2]

y0_3 = Y3[T3 == 0]
y1_3 = Y3[T3 == 1]
respuesta_3 = [y0_3, y1_3]

etiquetas = ["control", "tratados"]

# Crear los subplots
fig, axs = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle('Distribución de la respuesta por estatus de tratamiento')

# Gráfico para Kindergarten
axs[0, 0].boxplot(respuesta_k, labels=etiquetas)
axs[0, 0].set_title('Kindergarten')
axs[0, 0].set_ylabel('Valor de la respuesta')

# Gráfico para Primer Grado
axs[0, 1].boxplot(respuesta_1, labels=etiquetas)
axs[0, 1].set_title('Primer Grado')

# Gráfico para Segundo Grado
axs[1, 0].boxplot(respuesta_2, labels=etiquetas)
axs[1, 0].set_title('Segundo Grado')
axs[1, 0].set_ylabel('Valor de la respuesta')
axs[1, 0].set_xlabel('Tratamiento')

# Gráfico para Tercer Grado
axs[1, 1].boxplot(respuesta_3, labels=etiquetas)
axs[1, 1].set_title('Tercer Grado')
axs[1, 1].set_xlabel('Tratamiento')

# Ajustar diseño
plt.tight_layout()
plt.subplots_adjust(top=0.88, hspace=0.5)  # Ajustar espacio entre filas

plt.savefig("./images/boxplotRespuestaTratamiento.png", bbox_inches='tight', dpi=300)

# Mostrar el gráfico
plt.show()
```

![<strong>Figura 32. </strong> Distribución de la respuesta por estatus de tratamiento (clase regular vs clase reducida) en los diferentes cursos.](./images/boxplotRespuestaTratamiento.png)



### S-Learner

El S-Learner es un modelo de aprendizaje supervisado que utiliza un único modelo predictivo para estimar tanto el resultado con el tratamiento como sin él. Se entrena concretamente un modelo predictivo usando las características de los individuos y la variable tratamiento como predictores. Luego, este modelo se usa para predecir el resultado bajo ambas condiciones para cada individuo y se calcula la diferencia entre las predicciones para obtener el efecto del tratamiento.

Se estuvo probando con diferentes transformaciones, pero la que mejores resultados pudimos finalmente obtener era utilizando una transformación polinomial de grado 2 (`PolynomialFeatures`) con una regularización Lasso (L1), tras ajustar el valor del hiperparámetro `alpha`.

```{python SLearner-defining, include = FALSE}
#alpha = 0.2
#ridge_reg = Ridge(alpha=alpha)
poly = PolynomialFeatures(degree=2, include_bias=True)
linregLASSO =  Lasso(alpha=0.1)
overall_model = make_pipeline(poly, linregLASSO)

S_learner = SLearner(overall_model=overall_model)
```


```{python S-Learner-training, include = FALSE}
# Inicializar listas para almacenar resultados
all_te = []
all_ate_intervals = []
all_point_estimates = []
all_lb = []
all_ub = []
shap_values = []

# Listas de datos
Y_list = [Yk, Y1, Y2, Y3]
T_list = [Tk, T1, T2, T3]
X_list = [Xk, X1, X2, X3]
titles = ['Kindergarten', 'Primer Curso', 'Segundo Curso', 'Tercer Curso']

# Variable para controlar si es la primera iteración
first_iteration = True

# Entrenar el S-Learner y obtener efectos para cada conjunto de datos
for Y, T, X in zip(Y_list, T_list, X_list):

    S_learner.fit(Y, T, X=X, inference="bootstrap")
    
    # Estimar efectos de tratamiento
    S_te = S_learner.effect(X)
    all_te.append(S_te)
    
    # Obtener intervalo de confianza del ATE
    ate_interval = S_learner.ate_interval(X, T0=0, T1=1)
    all_ate_intervals.append(ate_interval)

    # Obtener intervalos de confianza para cada punto estimado
    lb, ub = S_learner.effect_interval(X)
    all_lb.append(lb)
    all_ub.append(ub)
    all_point_estimates.append(S_te)
    
    # Guardar SHAP values solo en la primera iteración
    if first_iteration:
        shap_values = S_learner.shap_values(X)
        first_iteration = False
```

```{python TE-SLearner, fig.cap = "<strong> Figura 33. </strong> Histograma de efectos de tratamiento estimados por el S-Learner en los diferentes cursos.", echo = FALSE, message = FALSE}
fig, axs = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle('Histogramas de efectos de tratamiento estimados', fontsize=16)

# Dibujar histogramas para cada conjunto de datos
for i, ax in enumerate(axs.flat):
    ax.hist(all_te[i], bins=30, color='blue', alpha=0.7)
    ax.set_title(titles[i], fontsize=16)
    ax.set_xlabel('Efecto de tratamiento', fontsize=14)
    ax.set_ylabel('Frecuencia', fontsize=14)

# Ajustar diseño
plt.tight_layout()
plt.subplots_adjust(top=0.9)  # Ajustar el espacio del título

# Mostrar el gráfico
plt.show()
```
```{python CI-SLearner, fig.cap = "<strong> Figura 34. </strong> Estimaciones de efectos de tratamiento y bandas de confianza en los diferentes cursos.", echo = FALSE, message = FALSE}
fig, axs = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle('Estimaciones de efectos de tratamiento y bandas de confianza', fontsize=16)

# Dibujar gráficos con barras de error para cada conjunto de datos
for i, ax in enumerate(axs.flat):
    df = pd.DataFrame({'point': all_point_estimates[i], 'lb': all_lb[i], 'ub': all_ub[i]})
    df = df.sort_values(by='point')
    yerr = [df['point'] - df['lb'], df['ub'] - df['point']]
    yerr = abs(pd.DataFrame(yerr))

    # Índices para el eje x
    x = range(len(df))

    # Dibujar los puntos centrales
    ax.plot(x, df['point'], 'o', label='Point')

    # Dibujar las bandas como barras de error
    ax.errorbar(x, df['point'], yerr=yerr.values, fmt='o', ecolor='lightgray', capsize=5, label='Confidence interval')

    # Añadir etiquetas y leyenda
    ax.set_title(titles[i], fontsize=16)
    ax.set_xlabel('Índice', fontsize=14)
    ax.set_ylabel('TE', fontsize=14)
    ax.legend()


plt.tight_layout()
plt.subplots_adjust(top=0.9) 

# Mostrar el gráfico
plt.show()
```
Puede observarse que las barras de error son significativamente grandes: resulta bastante incierto estimar el efecto del tratamiento para un individuo a pesar de todos los esfuerzos que hemos hecho por buscar modelos más robustos.


```{python ATE-SLearner-table, echo = FALSE, include = FALSE}
# Crear un DataFrame para una mejor visualización de los intervalos de confianza del ATE
ate_results = pd.DataFrame({
    "Curso": ['Kindergarten', 'Primer Curso', 'Segundo Curso', 'Tercer Curso'],
    "Lower Bound": [interval[0] for interval in all_ate_intervals],
    "ATE": [S_learner.ate(X) for X in X_list],
    "Upper Bound": [interval[1] for interval in all_ate_intervals]
})


fig, ax = plt.subplots(figsize=(8, 2))
ax.axis('off')
ax.axis('tight')

ax.table(cellText=ate_results.values, colLabels=ate_results.columns, cellLoc='center', loc='center')

plt.tight_layout()
plt.savefig("./images/ate_intervals_slearner.png", bbox_inches='tight', dpi=300) # guardo porque no se renderiza bien en el RMarkdown y siempre acaba printeando basura :(
plt.show()
```

![<strong>Figura 35. </strong> Intervalos de confianza para el ATE en los diferentes cursos usando el S-learner.](./images/ate_intervals_slearner.png)

Los resultados para el ATE están en la línea de lo que obtuvimos con los modelos de regresión anteriores, quizás algo por debajo. Sin embargo, si tenemos en cuenta los intervalos de confianza, sí que caería en lo que antes vimos.

Podemos a continuación observar los **SHAP values** (*Shapley Additive Explanations*), de tal forma que podamos entender el impacto de cada característica en la predicción de un modelo. Se mostrarán los resultados solo para Kindergarten en aras de la brevedad.

El gráfico *waterfall* muestra cómo se combinan los efectos de las características individuales para llegar a la predicción final. Cada barra representa el SHAP value de una característica, y se ordenan de mayor a menor impacto en la predicción.

```{python, echo = FALSE, include = FALSE}
plt.figure(figsize=(20, 8))
shap.plots.waterfall(shap_values['Y0']['T0_1.0'][0], max_display=20, show=False)

plt.savefig("./images/wfallSLearner_k.png", bbox_inches='tight', dpi=300)
```

![<strong>Figura 36. </strong> Gráfico de waterfall que indica cómo se da la combinación para la predicción final (Kindergarten) (Para la primera muestra).](./images/wfallSLearner_k.png)


El gráfico de barras muestra la importancia media de cada característica en el modelo. Este gráfico se crea sumando los valores absolutos de los SHAP values de cada característica a lo largo de todas las observaciones.

```{python, echo=FALSE, include = FALSE}
plt.figure(figsize=(20, 8))
shap.plots.bar(shap_values['Y0']['T0_1.0'], show = False)

plt.savefig("./images/barSLearner_k.png", bbox_inches='tight', dpi=300)
```

![<strong>Figura 37. </strong> Gráfico de barras con la importancia de cada característica (Kindergarten).](./images/barSLearner_k.png)


### X-learner

En el X-Learner, al igual que en el DR-Learner, se tienen dos etapas para estimar el efecto del tratamiento en una población. En la primera etapa se estiman las funciones *nuisance*, como la propensión al tratamiento y la respuesta potencial condicional, para generar una pseudorespuesta. En la segunda etapa, se ajusta un modelo de regresión usando la pseudorespuesta y las covariables para obtener una estimación final del CATE. Tras esto, puede realizarse la predicción.

En nuestro caso, usaremos el XLearner incorporando los modelos de `GradientBoostingRegressor` y `RandomForestClassifier` para las funciones nuisance y generación de pseudorespuesta. Se ha fijado un número de estimadores de 100 y una profundidad máxima de 10 para el modelo de regresión y de 6 para el modelo de clasificación.



```{python XLearner-defining, include = FALSE}
n = 10000
models = GradientBoostingRegressor(n_estimators=100, max_depth=10, min_samples_leaf=int(n/100), random_state=seed)
propensity_model = RandomForestClassifier(n_estimators=100, max_depth=6, 
                                                  min_samples_leaf=int(n/100), random_state=seed)
                                                  
X_learner = XLearner(models=models, propensity_model=propensity_model)
```

```{python XLearner-training, include = FALSE, eval = FALSE}
all_te_x = []  
all_ate_intervals_x = []  
all_point_estimates_x = []  
all_lb_x = []  
all_ub_x = []  
shap_values_x = []  

first_iteration_x = True

# Entrenar el XLearner y obtener efectos para cada conjunto de datos
for Y, T, X in zip(Y_list, T_list, X_list):

    X_learner.fit(Y, T, X=X, inference="bootstrap")
    
    # Estimar efectos de tratamiento
    X_te = X_learner.effect(X)
    all_te_x.append(X_te)
    
    # Obtener intervalo de confianza del ATE
    ate_interval_x = X_learner.ate_interval(X, T0=0, T1=1)
    all_ate_intervals_x.append(ate_interval_x)

    # Obtener intervalos de confianza para cada punto estimado
    lb_x, ub_x = X_learner.effect_interval(X)
    all_lb_x.append(lb_x)
    all_ub_x.append(ub_x)
    all_point_estimates_x.append(X_te)
    
    # Guardar SHAP values solo en la primera iteración
    
    if first_iteration_x:
        shap_values = X_learner.shap_values(X)
        first_iteration_x = False
```

```{python}
# Crear si no existe ./data/XLearner/
if not os.path.exists("./data/XLearner/"):
    os.makedirs("./data/XLearner/")
```


```{python}
def guardar_listas(all_te_x, all_ate_intervals_x, all_point_estimates_x, all_lb_x, all_ub_x, shap_values_x):
    # Guardar all_te_x
    with open('./data/XLearner/all_te_x.pkl', 'wb') as file:
        pickle.dump(all_te_x, file)
    
    # Guardar all_ate_intervals_x
    with open('./data/XLearner/all_ate_intervals_x.pkl', 'wb') as file:
        pickle.dump(all_ate_intervals_x, file)
    
    # Guardar all_point_estimates_x
    with open('./data/XLearner/all_point_estimates_x.pkl', 'wb') as file:
        pickle.dump(all_point_estimates_x, file)
    
    # Guardar all_lb_x
    with open('./data/XLearner/all_lb_x.pkl', 'wb') as file:
        pickle.dump(all_lb_x, file)
    
    # Guardar all_ub_x
    with open('./data/XLearner/all_ub_x.pkl', 'wb') as file:
        pickle.dump(all_ub_x, file)
    
    # Guardar shap_values_x
    with open('./data/XLearner/shap_values_x.pkl', 'wb') as file:
        pickle.dump(shap_values_x, file)
```

```{python}
guardar_listas(all_te_x, all_ate_intervals_x, all_point_estimates_x, all_lb_x, all_ub_x, shap_values_x)
```

```{python}
def cargar_listas():
    # Cargar all_te_x
    with open('./data/XLearner/all_te_x.pkl', 'rb') as file:
        all_te_x = pickle.load(file)
    
    # Cargar all_ate_intervals_x
    with open('./data/XLearner/all_ate_intervals_x.pkl', 'rb') as file:
        all_ate_intervals_x = pickle.load(file)
    
    # Cargar all_point_estimates_x
    with open('./data/XLearner/all_point_estimates_x.pkl', 'rb') as file:
        all_point_estimates_x = pickle.load(file)
    
    # Cargar all_lb_x
    with open('./data/XLearner/all_lb_x.pkl', 'rb') as file:
        all_lb_x = pickle.load(file)
    
    # Cargar all_ub_x
    with open('./data/XLearner/all_ub_x.pkl', 'rb') as file:
        all_ub_x = pickle.load(file)
    
    # Cargar shap_values_x
    with open('./data/XLearner/shap_values_x.pkl', 'rb') as file:
        shap_values_x = pickle.load(file)
    
    return all_te_x, all_ate_intervals_x, all_point_estimates_x, all_lb_x, all_ub_x, shap_values_x
```

```{python}
# Guardar X_learner
with open('./data/XLearner/X_learner.pkl', 'wb') as file:
    pickle.dump(X_learner, file)
```


```{python}
all_te_x, all_ate_intervals_x, all_point_estimates_x, all_lb_x, all_ub_x, shap_values_x = cargar_listas()

with open('./data/XLearner/X_learner.pkl', 'rb') as file:
    X_learner = pickle.load(file)
```



```{python, fig.cap = "<strong> Figura 38. </strong> Histograma de efectos de tratamiento estimados por el X-Learner en los diferentes cursos.", echo = FALSE, message = FALSE}
# Crear figura y subplots
fig, axs = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle('Histogramas de efectos de tratamiento estimados (XLearner)', fontsize=16)

# Dibujar histogramas para cada conjunto de datos
for i, ax in enumerate(axs.flat):
    ax.hist(all_te_x[i], bins=30, color='blue', alpha=0.7)
    ax.set_title(titles[i], fontsize=16)
    ax.set_xlabel('Efecto de tratamiento', fontsize=14)
    ax.set_ylabel('Frecuencia', fontsize=14)

# Ajustar diseño
plt.tight_layout()
plt.subplots_adjust(top=0.9)  # Ajustar el espacio del título

# Mostrar el gráfico
plt.show()
```

```{python, fig.cap = "<strong> Figura 39. </strong> Estimaciones de efectos de tratamiento y bandas de confianza en los diferentes cursos (XLearner).", echo = FALSE, message = FALSE}
# Crear figura y subplots
fig, axs = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle('Estimaciones de efectos de tratamiento y bandas de confianza (XLearner)', fontsize=16)

# Dibujar gráficos con barras de error para cada conjunto de datos
for i, ax in enumerate(axs.flat):
    df = pd.DataFrame({'point': all_point_estimates_x[i], 'lb': all_lb_x[i], 'ub': all_ub_x[i]})
    df = df.sort_values(by='point')
    yerr = [df['point'] - df['lb'], df['ub'] - df['point']]
    yerr = abs(pd.DataFrame(yerr))

    # Índices para el eje x
    x = range(len(df))

    # Dibujar los puntos centrales
    ax.plot(x, df['point'], 'o', label='Point')

    # Dibujar las bandas como barras de error
    ax.errorbar(x, df['point'], yerr=yerr.values, fmt='o', ecolor='lightgray', capsize=5, label='Confidence interval')

    # Añadir etiquetas y leyenda
    ax.set_title(titles[i], fontsize=16)
    ax.set_xlabel('Índice', fontsize=14)
    ax.set_ylabel('TE', fontsize=14)
    ax.legend()

# Ajustar diseño
plt.tight_layout()
plt.subplots_adjust(top=0.9)

# Mostrar el gráfico
plt.show()
```

```{python ATE-XLearner-table, echo = FALSE, include = FALSE}
ate_results_x = pd.DataFrame({
    "Curso": ['Kindergarten', 'Primer Curso', 'Segundo Curso', 'Tercer Curso'],
    "Lower Bound": [interval[0] for interval in all_ate_intervals_x],
    "ATE": [X_learner.ate(X) for X in X_list],
    "Upper Bound": [interval[1] for interval in all_ate_intervals_x]
})

# Crear figura y eje para la tabla
fig, ax = plt.subplots(figsize=(8, 2))
ax.axis('off')
ax.axis('tight')

# Crear la tabla y mostrarla
ax.table(cellText=ate_results_x.values, colLabels=ate_results_x.columns, cellLoc='center', loc='center')

# Ajustar el diseño y mostrar la tabla
plt.tight_layout()
plt.savefig("./images/ate_intervals_xlearner.png", bbox_inches='tight', dpi=300)
plt.show()
```

![<strong>Figura 40. </strong> Intervalos de confianza para el ATE en los diferentes cursos usando el X-learner.](./images/ate_intervals_xlearner.png)

```{python echo = FALSE, include = FALSE}
plt.figure(figsize=(20, 8))
shap.plots.waterfall(shap_values_x['Y0']['T0_1.0'][0], max_display=20, show=False)

plt.savefig("./images/wfallXLearner_k.png", bbox_inches='tight', dpi=300)
```

![<strong>Figura 41. </strong> Gráfico de waterfall que indica cómo se da la combinación para la predicción final (Kindergarten) (Para la primera muestra).](./images/wfallXLearner_k.png)




```{python echo = FALSE, include = FALSE}
plt.figure(figsize=(20, 8))
shap.plots.bar(shap_values_x['Y0']['T0_1.0'], show = False)

plt.savefig("./images/barXLearner_k.png", bbox_inches='tight', dpi=300)
```

![<strong>Figura 42. </strong> Gráfico de barras con la importancia de cada característica (Kindergarten).](./images/barXLearner_k.png)


```{python, eval = FALSE}
lb, ub = X_learner.effect_interval(xTest_k)

df = pd.DataFrame({'point': S_te,'lb':lb,'ub':ub})
df = df.sort_values(by='point')
yerr = [df['point'] - df['lb'], df['ub'] - df['point']]
yerr = abs(pd.DataFrame(yerr))

# Establecer el tamaño de la figura
plt.figure(figsize=(10, 6))

# Índices para el eje x
x = range(len(df))

# Dibujar los puntos centrales
plt.plot(x, df['point'], 'o', label='Point')

# Dibujar las bandas como barras de error
plt.errorbar(x, df['point'], yerr=yerr.values, fmt='o', ecolor='lightgray', capsize=5, label='Confidence interval')

# Añadir etiquetas y leyenda
plt.xlabel('Index')
plt.ylabel('Value')
plt.title('Point Values and Confidence Bands')
plt.legend()

# Mostrar el gráfico
plt.show()
```

```{python, eval = FALSE}
X_learner.ate_interval(xTest_k)
```

## Uso de DoubleML

```{python}
from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor
from doubleml import DoubleMLData
from xgboost import XGBClassifier, XGBRegressor
from doubleml import DoubleMLPLR
```


*Añadir explicación de DoubleML y cómo funciona básicamente.*

```{python}
def run_dml_analysis(data, y_col, d_cols, ml_l_rf, ml_l_xgb, ml_m_rf, ml_m_xgb, grupos=None, curso=None, n_folds=10, show_summary=True):
  
    # Definir datos para DoubleML
    dml_data = DoubleMLData(data, y_col=y_col, d_cols=d_cols)

    # Inicializar modelos DoubleMLPLR con RandomForest y ajuste
    dml_plr_rf = DoubleMLPLR(dml_data, ml_l=ml_l_rf, ml_m=ml_m_rf, n_folds=n_folds)
    dml_plr_rf.fit()

    # Inicializar modelos DoubleMLPLR con XGBoost y ajuste
    dml_plr_xgb = DoubleMLPLR(dml_data, ml_l=ml_l_xgb, ml_m=ml_m_xgb, n_folds=n_folds)
    dml_plr_xgb.fit()
    
    # Resumen de resultados de ambos:
    if show_summary:
        print("============= INFORMACIÓN PARA {} =============".format(curso))
        print("Summary RandomForest:")
        print(dml_plr_rf.summary)
        print("\nSummary XGBoost:")
        print(dml_plr_xgb.summary)
  
    # Calcular efectos condicionales (GATE)
    if grupos is not None:
    # GATE con RandomForest
      gate_rf = dml_plr_rf.gate(groups=grupos)
      #print("\nGATE RandomForest " + curso + ":")
      #print(gate_rf.confint(level=0.95))

      ci_rf = gate_rf.confint(level=0.95, joint=False)

    # Calcular errores para barras de error de RandomForest
      errors_rf = np.full((2, ci_rf.shape[0]), np.nan)
      errors_rf[0, :] = ci_rf['effect'] - ci_rf['2.5 %']
      errors_rf[1, :] = ci_rf['97.5 %'] - ci_rf['effect']

    # GATE con XGBoost
      gate_xgb = dml_plr_xgb.gate(groups=grupos)
      #print("\nGATE XGBoost " + curso + ":")
      #print(gate_xgb.confint(level=0.95))

      ci_xgb = gate_xgb.confint(level=0.95, joint=False)

    # Calcular errores para barras de error de XGBoost
      errors_xgb = np.full((2, ci_xgb.shape[0]), np.nan)
      errors_xgb[0, :] = ci_xgb['effect'] - ci_xgb['2.5 %']
      errors_xgb[1, :] = ci_xgb['97.5 %'] - ci_xgb['effect']


      fig, axs = plt.subplots(1, 2, figsize=(20, 6))
      
      titleFontSize = 22
      labelsFontSize = 18
      legendFontSize = 16
      
    # Graficar barras de error para RandomForest
    
      axs[0].errorbar(ci_rf.index, ci_rf.effect, fmt='o', yerr=errors_rf, label='Efecto estimado (IC conjunto) RandomForest')
      axs[0].set_title('GATEs RandomForest ' + curso, fontsize=titleFontSize)
      axs[0].set_xlabel('Grupos', fontsize=labelsFontSize)
      axs[0].set_ylabel('Effect and 95%-CI', fontsize=labelsFontSize)
      axs[0].legend(fontsize=legendFontSize)
      axs[0].tick_params(axis='both', which = 'major', labelsize=labelsFontSize)

    # Graficar barras de error para XGBoost
      axs[1].errorbar(ci_xgb.index, ci_xgb.effect, fmt='o', yerr=errors_xgb, label='Efecto estimado (IC conjunto) XGBoost')
      axs[1].set_title('GATEs XGBoost ' + curso, fontsize=titleFontSize)
      axs[1].set_xlabel('Grupos', fontsize=labelsFontSize)
      axs[1].set_ylabel('Effect and 95%-CI', fontsize=labelsFontSize)
      axs[1].legend(fontsize=legendFontSize)
      axs[1].tick_params(axis='both', which = 'major', labelsize=labelsFontSize)

      plt.tight_layout()
      plt.show()

    return dml_plr_rf, dml_plr_xgb

```

```{python, eval = FALSE}
ml_m_rf = RandomForestRegressor(random_state=seed)
ml_e_rf = RandomForestClassifier(random_state=seed)
ml_m_xgb = XGBRegressor(objective="reg:squarederror", random_state=seed)
ml_e_xgb = XGBClassifier(use_label_encoder=False, objective="binary:logistic", eval_metric="logloss", random_state=seed)
```

### Group Average Treatment Effects (GATEs)

#### Efecto del tratamiento por etnia


```{python eval = FALSE}
grupos_k = pd.DataFrame(np.column_stack((starDf_k['ethnicity_grouped'] == 1, starDf_k['ethnicity_grouped'] == 0)), columns=['cauc', 'afam+other'])
grupos_1 = pd.DataFrame(np.column_stack((starDf_1['ethnicity_grouped'] == 1, starDf_1['ethnicity_grouped'] == 0)), columns=['cauc', 'afam+other'])
grupos_2 = pd.DataFrame(np.column_stack((starDf_2['ethnicity_grouped'] == 1, starDf_2['ethnicity_grouped'] == 0)), columns=['cauc', 'afam+other'])
grupos_3 = pd.DataFrame(np.column_stack((starDf_3['ethnicity_grouped'] == 1, starDf_3['ethnicity_grouped'] == 0)), columns=['cauc', 'afam+other'])


dml_plr_rf_k, dml_plr_xgb_k = run_dml_analysis(data=starDf_k,
                                           y_col='markK',
                                           d_cols='stark',
                                           ml_l_rf=ml_m_rf,
                                           ml_l_xgb=ml_m_xgb,
                                           ml_m_rf=ml_e_rf,
                                           ml_m_xgb=ml_e_xgb,
                                           grupos=grupos_k,
                                           curso = "Kindergarten",
                                           n_folds=10)

dml_plr_rf_1, dml_plr_xgb_1 = run_dml_analysis(data=starDf_1,
                                           y_col='mark1',
                                           d_cols='star1',
                                           ml_l_rf=ml_m_rf,
                                           ml_l_xgb=ml_m_xgb,
                                           ml_m_rf=ml_e_rf,
                                           ml_m_xgb=ml_e_xgb,
                                           grupos=grupos_1,
                                           curso = "1st Grade",
                                           n_folds=10)
                                           
dml_plr_rf_2, dml_plr_xgb_2 = run_dml_analysis(data=starDf_2,
                                           y_col='mark2',
                                           d_cols='star2',
                                           ml_l_rf=ml_m_rf,
                                           ml_l_xgb=ml_m_xgb,
                                           ml_m_rf=ml_e_rf,
                                           ml_m_xgb=ml_e_xgb,
                                           grupos=grupos_2,
                                           curso = "2nd Grade",
                                           n_folds=10)
                                           
dml_plr_rf_3, dml_plr_xgb_3 = run_dml_analysis(data=starDf_3,
                                           y_col='mark3',
                                           d_cols='star3',
                                           ml_l_rf=ml_m_rf,
                                           ml_l_xgb=ml_m_xgb,
                                           ml_m_rf=ml_e_rf,
                                           ml_m_xgb=ml_e_xgb,
                                           grupos=grupos_3,
                                           curso = "3rd Grade",
                                           n_folds=10)
```

#### Efecto del tratamiento por género

```{python eval = FALSE}
grupos_k = pd.DataFrame(np.column_stack((starDf_k['gender'] == 1, starDf_k['gender'] == 0)), columns=['female', 'male'])
grupos_1 = pd.DataFrame(np.column_stack((starDf_1['gender'] == 1, starDf_1['gender'] == 0)), columns=['female', 'male'])
grupos_2 = pd.DataFrame(np.column_stack((starDf_2['gender'] == 1, starDf_2['gender'] == 0)), columns=['female', 'male'])
grupos_3 = pd.DataFrame(np.column_stack((starDf_3['gender'] == 1, starDf_3['gender'] == 0)), columns=['female', 'male'])

dml_plr_rf_k, dml_plr_xgb_k = run_dml_analysis(data=starDf_k,
                                           y_col='markK',
                                           d_cols='stark',
                                           ml_l_rf=ml_m_rf,
                                           ml_l_xgb=ml_m_xgb,
                                           ml_m_rf=ml_e_rf,
                                           ml_m_xgb=ml_e_xgb,
                                           grupos=grupos_k,
                                           curso = "Kindergarten",
                                           n_folds=10)

dml_plr_rf_1, dml_plr_xgb_1 = run_dml_analysis(data=starDf_1,
                                           y_col='mark1',
                                           d_cols='star1',
                                           ml_l_rf=ml_m_rf,
                                           ml_l_xgb=ml_m_xgb,
                                           ml_m_rf=ml_e_rf,
                                           ml_m_xgb=ml_e_xgb,
                                           grupos=grupos_1,
                                           curso = "1st Grade",
                                           n_folds=10)
                                           
dml_plr_rf_2, dml_plr_xgb_2 = run_dml_analysis(data=starDf_2,
                                           y_col='mark2',
                                           d_cols='star2',
                                           ml_l_rf=ml_m_rf,
                                           ml_l_xgb=ml_m_xgb,
                                           ml_m_rf=ml_e_rf,
                                           ml_m_xgb=ml_e_xgb,
                                           grupos=grupos_2,
                                           curso = "2nd Grade",
                                           n_folds=10)
                                           
dml_plr_rf_3, dml_plr_xgb_3 = run_dml_analysis(data=starDf_3,
                                           y_col='mark3',
                                           d_cols='star3',
                                           ml_l_rf=ml_m_rf,
                                           ml_l_xgb=ml_m_xgb,
                                           ml_m_rf=ml_e_rf,
                                           ml_m_xgb=ml_e_xgb,
                                           grupos=grupos_3,
                                           curso = "3rd Grade",
                                           n_folds=10)
```

#### Efecto del tratamiento por tipo de escuela

```{python eval = FALSE}
# Hay 4 grupos, 'inner-city', 'suburban', 'rural', 'urban'
grupos_k = pd.DataFrame(np.column_stack((starDf_k['schoolk_inner-city'] == 1, starDf_k['schoolk_suburban'] == 1, starDf_k['schoolk_rural'] == 1, starDf_k['schoolk_urban'] == 1)), columns=['inner-city', 'suburban', 'rural', 'urban'])
grupos_1 = pd.DataFrame(np.column_stack((starDf_1['school1_inner-city'] == 1, starDf_1['school1_suburban'] == 1, starDf_1['school1_rural'] == 1, starDf_1['school1_urban'] == 1)), columns=['inner-city', 'suburban', 'rural', 'urban'])
grupos_2 = pd.DataFrame(np.column_stack((starDf_2['school2_inner-city'] == 1, starDf_2['school2_suburban'] == 1, starDf_2['school2_rural'] == 1, starDf_2['school2_urban'] == 1)), columns=['inner-city', 'suburban', 'rural', 'urban'])

grupos_3 = pd.DataFrame(np.column_stack((starDf_3['school3_inner-city'] == 1, starDf_3['school3_suburban'] == 1, starDf_3['school3_rural'] == 1, starDf_3['school3_urban'] == 1)), columns=['inner-city', 'suburban', 'rural', 'urban'])

dml_plr_rf_k, dml_plr_xgb_k = run_dml_analysis(data=starDf_k,
                                           y_col='markK',
                                           d_cols='stark',
                                           ml_l_rf=ml_m_rf,
                                           ml_l_xgb=ml_m_xgb,
                                           ml_m_rf=ml_e_rf,
                                           ml_m_xgb=ml_e_xgb,
                                           grupos=grupos_k,
                                           curso = "Kindergarten",
                                           n_folds=10)

dml_plr_rf_1, dml_plr_xgb_1 = run_dml_analysis(data=starDf_1,
                                           y_col='mark1',
                                           d_cols='star1',
                                           ml_l_rf=ml_m_rf,
                                           ml_l_xgb=ml_m_xgb,
                                           ml_m_rf=ml_e_rf,
                                           ml_m_xgb=ml_e_xgb,
                                           grupos=grupos_1,
                                           curso = "1st Grade",
                                           n_folds=10)
                                           
dml_plr_rf_2, dml_plr_xgb_2 = run_dml_analysis(data=starDf_2,
                                           y_col='mark2',
                                           d_cols='star2',
                                           ml_l_rf=ml_m_rf,
                                           ml_l_xgb=ml_m_xgb,
                                           ml_m_rf=ml_e_rf,
                                           ml_m_xgb=ml_e_xgb,
                                           grupos=grupos_2,
                                           curso = "2nd Grade",
                                           n_folds=10)
                                           
dml_plr_rf_3, dml_plr_xgb_3 = run_dml_analysis(data=starDf_3,
                                           y_col='mark3',
                                           d_cols='star3',
                                           ml_l_rf=ml_m_rf,
                                           ml_l_xgb=ml_m_xgb,
                                           ml_m_rf=ml_e_rf,
                                           ml_m_xgb=ml_e_xgb,
                                           grupos=grupos_3,
                                           curso = "3rd Grade",
                                           n_folds=10)


```
ETNIA:

Parece que los grupos no caucásicos se benefician en mayor medida del hecho de estar en clases más reducidas, el único curso donde el efecto tratamiento no muestra diferencias significativas es en el primer curso como se observa en el gráfico, si bien es cierto que como se describe en el artículo sobre STAR, hubo cambios en la asignación en el primer curso, pudiendo alterar potencialmente los resultados, sin embargo, no tenemos ninguna certidumbre de que el motivo de la no heteregeneidad sea esa.

GENERO:

En este caso observamos que los hombres se habrían beneficiado más del tratamiento que las mujeres, pero, al igual que para la variable etnia, en el primer curso, la tendencia se revierte, donde las mujeres se beneficiarían más del tratamiento. Para el resto de cursos, los hombres se beneficiarian más que las mujeres, lo que podría parecer contraintuitivo.

SCHOOL LOCATION:

El p-valor de los modelos DoubleML es significativo al 99% para todos los cursos con unos coeficientes que tienen valores razonables, entre 12 y 22 puntos como efecto tratamiento, lo que llama la atención es la evolución de los efectos heterogeneos, entre un modelo xgboost y un random forest no se observan diferencias apreciables. En kindergarten, se aprecia mayor efecto tratamiento en los colegios de los barrios urbanos e inner-city, en primero, los mayores efectos se aprecian en los barrios urbanos y sub-urbanos, en segundo sin embargo el efecto de los barrios urbanos es negativo pero con gran variabilidad lo cual indica que probablemente el ajuste de esa variable no sea correcto, el efecto mayor se observa en los barrios inner-city. En tercero el resultado es similar a segundo. Los resultados que se obtienen nos pueden indicar que los barrios inner-city serían en los que mayor efecto tratamiento presentan y tras ellos los barrios urbanos, aunque para los dos últimos años no podemos obtener resultados concluyentes. Los colegios ubicados en zonas rurales serían los que menor efecto tratamiento presentan.



# Referencias {#referencias}
